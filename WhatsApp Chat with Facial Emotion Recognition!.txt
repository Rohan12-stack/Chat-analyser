05/11/24, 11:02 - Messages and calls are end-to-end encrypted. Only people in this chat can read, listen to, or share them. Learn more.
19/08/24, 20:10 - You created this group
20/11/24, 14:42 - rohxn 03: We need 3 things for fridays submission 

1. Course Project
2. Report in IEEE Format
3. Presentation
21/11/24, 10:19 - Wifeyâ¤ï¸: <Media omitted>
21/11/24, 10:47 - Wifeyâ¤ï¸: https://www.slideshare.net/slideshow/attendance-management-system-using-face-recognition/249852705
21/11/24, 10:47 - Wifeyâ¤ï¸: https://www.slideshare.net/slideshow/face-recognition-attendance-system-85321885/85321885
22/11/24, 10:03 - Wifeyâ¤ï¸: <Media omitted>
22/11/24, 10:03 - rohxn 03: Nishita and ammu.... Pls do check this ppt and tell me if there is any error ok....
Before submission
22/11/24, 10:10 - Wifeyâ¤ï¸: <Media omitted>
22/11/24, 10:10 - rohxn 03: So ppl overall everything is doneğŸ˜
22/11/24, 10:11 - rohxn 03: Just submit
22/11/24, 10:21 - Gass: <Media omitted>
22/11/24, 10:22 - Gass: In final project submission right?
27/01/25, 19:49 - rohxn 03: Seriously what the hell she is even reading
27/01/25, 19:49 - rohxn 03: Priya palğŸ˜­
27/01/25, 19:49 - Wifeyâ¤ï¸: ayyoo
27/01/25, 19:49 - Gass: Wt happened da myre
27/01/25, 19:50 - rohxn 03: Nothing daa.... The online class we r listening
27/01/25, 19:50 - Wifeyâ¤ï¸: she is from north ig
27/01/25, 19:50 - Gass: Which online class
27/01/25, 19:50 - Wifeyâ¤ï¸: soo she cant read it properly
27/01/25, 19:50 - rohxn 03: Yeah...... Sport vector antha
Its support vector ğŸ˜­
27/01/25, 19:50 - Wifeyâ¤ï¸: we paid ryt 3600 that one
27/01/25, 19:50 - Gass: Oh okkk
27/01/25, 19:50 - Gass: Enjoy
27/01/25, 19:51 - Gass: <Media omitted>
27/01/25, 19:51 - Wifeyâ¤ï¸: and this one classification allaaa kilasification
27/01/25, 19:51 - rohxn 03: ğŸ˜­ğŸ˜­
27/01/25, 19:51 - rohxn 03: I didn't understand a thing
27/01/25, 19:51 - Wifeyâ¤ï¸: karmaa
27/01/25, 19:51 - Gass: <Media omitted>
27/01/25, 20:04 - Wifeyâ¤ï¸: nishitaa
27/01/25, 20:04 - Wifeyâ¤ï¸: y u didn't respond ahh
27/01/25, 20:04 - Wifeyâ¤ï¸: ğŸ¤­
27/01/25, 20:04 - rohxn 03: She is in some other duniyağŸ˜­
27/01/25, 20:06 - Nishita ğŸª°: U read ??
27/01/25, 20:06 - Wifeyâ¤ï¸: achu read I didn't readğŸ˜†
27/01/25, 20:08 - Nishita ğŸª°: I am not able to understand
27/01/25, 20:08 - Nishita ğŸª°: Y his making everyone read
27/01/25, 20:08 - Gass: <Media omitted>
27/01/25, 20:09 - Wifeyâ¤ï¸: who knows ayyo
27/01/25, 20:09 - Gass: <Media omitted>
27/01/25, 20:12 - rohxn 03: Hey i just went to peee......
And he is taking biology
27/01/25, 20:12 - rohxn 03: What happenedğŸ˜­ğŸ˜­
27/01/25, 20:12 - rohxn 03: Yaaavoooo........ ğŸ‘‰ğŸ»ğŸ‘ˆğŸ»
27/01/25, 20:12 - Gass: <Media omitted>
27/01/25, 20:12 - Wifeyâ¤ï¸: correct
27/01/25, 20:12 - rohxn 03: ğŸ˜
27/01/25, 20:13 - Nishita ğŸª°: He is talking in terms of bioinformatics
27/01/25, 20:13 - Gass: Myre try this
27/01/25, 20:13 - Gass: Guna no cheating
27/01/25, 20:14 - rohxn 03: <Media omitted>
27/01/25, 20:14 - Wifeyâ¤ï¸: ahh illa illa he will read
27/01/25, 20:14 - Gass: Try try
27/01/25, 20:14 - rohxn 03: This shit is soo fancy.... Cant read a letterğŸ˜­
27/01/25, 20:14 - Gass: If its wrong also no problem
27/01/25, 20:15 - Gass: Just a try wtever you can
27/01/25, 20:15 - rohxn 03: Try giving normal txt can u
Lemme try
27/01/25, 20:15 - Gass: Ok wait
27/01/25, 20:15 - rohxn 03: To try..... First i have to understand what the shit they wrote rigjtğŸ˜­
27/01/25, 20:15 - Gass: <Media omitted>
27/01/25, 20:15 - Gass: This
27/01/25, 20:16 - rohxn 03: Same font ryt
Try giving google pics.... So better font it would be
27/01/25, 20:16 - Gass: à²’à²‚à²¦à³ à²¬à³‡à²µà²°à³à²¸à²¿ à²•à³à²¡à³à²•
27/01/25, 20:16 - Gass: It's the same
27/01/25, 20:16 - rohxn 03: Ok ok
27/01/25, 20:16 - Gass: Try it now
27/01/25, 20:18 - rohxn 03: Endu bevarsi kuduka?
27/01/25, 20:19 - Wifeyâ¤ï¸: 1st word is wrong
27/01/25, 20:19 - Wifeyâ¤ï¸: endu allaa
27/01/25, 20:19 - rohxn 03: First letter is aa ee u u that shit ryt
27/01/25, 20:19 - Wifeyâ¤ï¸: no
27/01/25, 20:19 - rohxn 03: I dont know swarakshara that much
27/01/25, 20:19 - rohxn 03: Bha??
27/01/25, 20:19 - Wifeyâ¤ï¸: it is ondu
27/01/25, 20:19 - Gass: First letter is o
27/01/25, 20:20 - Wifeyâ¤ï¸: ondu means one
27/01/25, 20:20 - rohxn 03: ğŸ¤¨ğŸ¤¨ğŸ¤¨thats what i told ryt aa ee uu anthağŸ¤¨
27/01/25, 20:20 - rohxn 03: Ooooooo ok ok
27/01/25, 20:20 - Wifeyâ¤ï¸: okok learn slowly no rush
27/01/25, 20:20 - rohxn 03: Kuduka means?
27/01/25, 20:20 - Gass: Yeah It means ur one bevarsi kuduka ğŸ»
27/01/25, 20:21 - Wifeyâ¤ï¸: he will drink alottttttttttttttttt
27/01/25, 20:21 - rohxn 03: <Media omitted>
27/01/25, 20:21 - rohxn 03: Ooooo ok ok
27/01/25, 20:22 - Gass: <Media omitted>
27/01/25, 20:22 - rohxn 03: Write like this
27/01/25, 20:23 - Gass: à²«à²¸à³à²Ÿà³ à²¸à³à²Ÿà³‡à²œà³
27/01/25, 20:23 - Gass: It's actually english in Kannada lettersğŸ˜‚
27/01/25, 20:23 - rohxn 03: Ok ok
27/01/25, 20:23 - rohxn 03: Lemme guess
27/01/25, 20:24 - Wifeyâ¤ï¸: u 2 ppl separate agi txt madi because amma idare soo i cant delete each message
27/01/25, 20:24 - rohxn 03: First stage?
27/01/25, 20:24 - rohxn 03: Ok okğŸ˜†
27/01/25, 20:24 - Gass: Yeah
27/01/25, 20:24 - rohxn 03: <Media omitted>
27/01/25, 20:24 - Wifeyâ¤ï¸: correct
27/01/25, 20:24 - Wifeyâ¤ï¸: oh gof
27/01/25, 20:24 - Gass: <Media omitted>
27/01/25, 20:24 - Wifeyâ¤ï¸: okay okay txt separately ppl'sssssssss
27/01/25, 20:24 - rohxn 03: <Media omitted>
27/01/25, 20:24 - rohxn 03: Ok
27/01/25, 20:25 - Gass: Enough lesson for today
27/01/25, 20:25 - Gass: Let's continue tomorrow
27/01/25, 20:25 - Gass: <Media omitted>
15/02/25, 18:42 - rohxn 03: <Media omitted>
17/02/25, 18:25 - rohxn 03: *AICTE AND MSME Internship Opportunity @ IIT & IIM  IBM TOP MNCs is Now Open* ğŸŒŸğŸ“

*The AICTE and MSME have announced an exciting internship opportunity for students. This program offers a stipend of â‚¹20,000-â‚¹25,000 which can significantly help in covering your semester fees.* ğŸ’°âœ¨

*EXTRA BENEFITSğŸ‘‡ğŸ»* ğŸ

*- AICTE & ISO Approved internship completion certificates* ğŸ“œ 
*- Letter of recommendation for your jobs and higher studies* ğŸ“„ğŸ† 
*- Placement assistance (Mock interview and aptitude tests)* ğŸ“ğŸ¯

*Limited seats available! Scholarships for the first registered students!* ğŸš€ğŸ§‘â€ğŸ“

*Join the group below for more details* ğŸ“‹âœï¸

https://chat.whatsapp.com/GREixAhDRoILrVMnfhHMka

*Scholarships apply for each and every student. APPLY NOW AND TAKE A STEP TOWARDS A BRIGHTER FUTURE!* ğŸŒŸğŸš€
27/02/25, 11:45 - Wifeyâ¤ï¸ changed the group name from "Internship-II(Smart Attendance ğŸ“¸)" to "Facial Emotion Recognition!"
27/02/25, 11:45 - Wifeyâ¤ï¸: <Media omitted>
27/02/25, 11:46 - Wifeyâ¤ï¸: This is tomorrows ppt
27/02/25, 11:46 - Wifeyâ¤ï¸: Nishita and Ammu pls do make this change:
1. first slide give our name and USN <This message was edited>
27/02/25, 11:48 - Wifeyâ¤ï¸: 2. Complete problem statement slide
27/02/25, 11:48 - Wifeyâ¤ï¸: 3. ive done 3 literature work, in that the 2nd literature survey, pls add any image regarding that paper
27/02/25, 11:50 - Wifeyâ¤ï¸: And last task:
Ammu and Nishita, give a quick scan through our ppt and check for any spelling mistakes or suggest anything to remove or add
27/02/25, 21:31 - rohxn 03: @919663957450  and @918799146002 ...... Pls do the above task
Then only we can assign slides for each person
27/02/25, 22:02 - rohxn 03: Ppl atleast respondğŸ¤¦ğŸ»â€â™‚ï¸
Karma
27/02/25, 22:20 - Nishita ğŸª°: https://ieeexplore.ieee.org/abstract/document/9074302
27/02/25, 22:21 - Wifeyâ¤ï¸: https://www.sciencedirect.com/science/article/pii/S1319157818303379
27/02/25, 22:22 - Wifeyâ¤ï¸: https://www.sciencedirect.com/science/article/abs/pii/S0169260722000062?via%3Dihub
27/02/25, 22:34 - Wifeyâ¤ï¸: <Media omitted>
27/02/25, 22:34 - Wifeyâ¤ï¸: Nishitaa this is application slide, include this ppt, after literature survey
27/02/25, 22:36 - Wifeyâ¤ï¸: Objective and Motivation

There are several areas where emotion recognition techniques are used, like in digital cameras to automatically take pictures when the user smiles.

However, the most promising applications involve the humanization of artificial intelligent systems. If computers are able to keep track of the mental state of the user, robots can react upon this and behave appropriately. Emotion recognition, therefore, plays a key role in improving human-machine interaction.

Focusing on the objective, using a neural network-based artificially intelligent system capable of deriving the emotion of a person through pictures of his or her face.
27/02/25, 22:37 - Wifeyâ¤ï¸: dont put the title as "Objective and Motivation
", instead "Objectives" is fyn
27/02/25, 23:33 - Nishita ğŸª°: <Media omitted>
27/02/25, 23:36 - Nishita ğŸª°: Rohan should explain the slides : Introduction, Problem Statement and Applications
Guna should explain the slides: Dataset and Objective
Rohith should explain: Literature Survey (3 slides)
Remaining I will explain
27/02/25, 23:36 - Nishita ğŸª°: React to this msg with ğŸ‘ <This message was edited>
28/02/25, 00:01 - rohxn 03: Rohan should explain the slides : Introduction, Problem Statement
Guna should explain the slides: Dataset and Objective
Rohith should explain: Literature Survey (3 slides)
Applications and conclusion NishitağŸ˜Š
28/02/25, 00:02 - rohxn 03: React with booty emoji!!ğŸ¤ŒğŸ»
28/02/25, 00:08 - Gass: Fire in the bootyğŸ˜ğŸ”¥
28/02/25, 09:27 - Wifeyâ¤ï¸: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
28/02/25, 10:44 - Nishita ğŸª°: <Media omitted>
04/03/25, 19:40 - rohxn 03: People tomorrow we r presenting our ppt
So all of u should prepare ur part of the slide and come 
@916364562073  u have to be there in class the whole day
As we dont know when we have to present.... After presentation u leave
04/03/25, 19:40 - Wifeyâ¤ï¸: oky
04/03/25, 19:42 - Gass: I will be there myre
04/03/25, 19:42 - Gass: When I have came out in between in that guys class ğŸ˜’
04/03/25, 19:42 - Gass: I only play in Manish classes ğŸ˜‚
04/03/25, 19:43 - rohxn 03: @918799146002 try running the other code exp 2
And see howz the result coming
If we got any preliminary result which is more convincing than the first
We can update
Sooo.....

React with booty emogi if u sawğŸ˜’
04/03/25, 19:43 - rohxn 03: ğŸ˜­ğŸ˜­
No im telling don't go to ur room quickly antha
04/03/25, 19:44 - Gass: <Media omitted>
04/03/25, 19:47 - Nishita ğŸª°: Should I use jupyter nb or colab ??
04/03/25, 20:01 - rohxn 03: JN is fyn
04/03/25, 23:36 - Nishita ğŸª°: Rohan
04/03/25, 23:36 - rohxn 03: Yeah
04/03/25, 23:36 - Nishita ğŸª°: I have ran all codes of exp2
04/03/25, 23:36 - rohxn 03: Howzit
04/03/25, 23:37 - Nishita ğŸª°: We are getting 98 and 93 accuracy
04/03/25, 23:37 - rohxn 03: <Media omitted>
04/03/25, 23:37 - Nishita ğŸª°: Like it is train and validation accuracy
04/03/25, 23:37 - rohxn 03: Ok fine.... Which model it is
04/03/25, 23:37 - rohxn 03: Which algo. Is used
04/03/25, 23:37 - rohxn 03: Cnn?
04/03/25, 23:38 - Nishita ğŸª°: Yaa
04/03/25, 23:38 - Nishita ğŸª°: And one code is matching ml algo code
04/03/25, 23:38 - rohxn 03: Can we plot a confusion matrix out of it??
04/03/25, 23:38 - Nishita ğŸª°: Yes I think so
04/03/25, 23:38 - rohxn 03: Didnt understood
04/03/25, 23:39 - Nishita ğŸª°: <Media omitted>
04/03/25, 23:39 - Nishita ğŸª°: This one...
04/03/25, 23:39 - rohxn 03: Not today sleep now
Tomorrow we will plot confusion matrix do the evaluation part
04/03/25, 23:39 - Nishita ğŸª°: Okk
04/03/25, 23:39 - rohxn 03: Done!!
04/03/25, 23:39 - rohxn 03: We will use exp 2 code then
04/03/25, 23:39 - Nishita ğŸª°: For preliminary result we can use this
04/03/25, 23:39 - rohxn 03: Yep
04/03/25, 23:40 - Nishita ğŸª°: Ok sir ğŸ‘
04/03/25, 23:40 - Nishita ğŸª°: You can cp2 timetable ??
04/03/25, 23:40 - rohxn 03: Yes i can
04/03/25, 23:40 - rohxn 03: What i canğŸ˜­
04/03/25, 23:40 - Nishita ğŸª°: This message was deleted
04/03/25, 23:40 - rohxn 03: ğŸ¤¨ğŸ¤¨ğŸ¤¨
04/03/25, 23:40 - rohxn 03: Whaaat
04/03/25, 23:41 - rohxn 03: What me too
04/03/25, 23:41 - rohxn 03: I didn't understood
04/03/25, 23:41 - rohxn 03: Ur drunkğŸ¤¨ğŸ¤¨
04/03/25, 23:41 - Nishita ğŸª°: Meaning two exams a day
04/03/25, 23:41 - rohxn 03: Haa yass yasss
04/03/25, 23:41 - Wifeyâ¤ï¸: Is that u saw the cp2 timetable??
04/03/25, 23:41 - rohxn 03: ğŸ˜†
04/03/25, 23:41 - Nishita ğŸª°: Yes I forgot to put that word
04/03/25, 23:42 - rohxn 03: Nale inda shuru maadbekkuğŸ¤ŒğŸ»
04/03/25, 23:42 - rohxn 03: Ass bite
04/03/25, 23:42 - Gass: <Media omitted>
04/03/25, 23:42 - rohxn 03: Ok then lemme have a seggzeee sleeep
04/03/25, 23:42 - rohxn 03: Daaattaaaaaaaa
04/03/25, 23:42 - rohxn 03: Gunnite
04/03/25, 23:43 - Gass: <Media omitted>
04/03/25, 23:43 - Nishita ğŸª°: ğŸ’¤ğŸ‘‹
04/03/25, 23:43 - Wifeyâ¤ï¸: Byebye good nightğŸŒ™
05/03/25, 09:35 - rohxn 03: Ppl, be there in class at 10 15
Especially @918799146002 

We need to do the code and update ppt(preliminary slide)
05/03/25, 10:56 - Nishita ğŸª°: <Media omitted>
05/03/25, 12:05 - Nishita ğŸª°: <Media omitted>
05/03/25, 14:22 - Nishita ğŸª°: <Media omitted>
05/03/25, 14:22 - Nishita ğŸª°: <Media omitted>
05/03/25, 14:36 - Gass: Myre when are we presenting
05/03/25, 14:36 - Gass: What time should I be there?
05/03/25, 14:39 - Wifeyâ¤ï¸: Come now
05/03/25, 14:39 - Wifeyâ¤ï¸: We will  Leave in 10 mins
05/03/25, 14:39 - Gass: Okay
05/03/25, 14:44 - Wifeyâ¤ï¸: <Media omitted>
05/03/25, 15:05 - rohxn 03: We got 3 literature surveys from google scholars, which are published after 2020

Names....
05/03/25, 15:05 - rohxn 03: They also  used  ferc 2013 dataset
05/03/25, 15:41 - Nishita ğŸª°: Vision Transformers (ViTs) â€“ ViT models trained on emotion datasets can achieve state-of-the-art results.
DAN (Deep Attention Network) â€“ Focuses on attention mechanisms to improve FER accuracy.
13/03/25, 17:07 - rohxn 03: <Media omitted>
13/03/25, 17:07 - rohxn 03: Read this and tell is it worth
13/03/25, 17:07 - rohxn 03: What are ur opinions
13/03/25, 17:28 - Nishita ğŸª°: We have to attend this cie is there for this
13/03/25, 17:29 - Wifeyâ¤ï¸: cie??
13/03/25, 17:29 - rohxn 03: This workshop is a must??
13/03/25, 17:30 - Nishita ğŸª°: It is 2 credits
13/03/25, 17:30 - Nishita ğŸª°: They mentioned
13/03/25, 17:30 - rohxn 03: Yeah i know
13/03/25, 17:30 - rohxn 03: But this is not must ryt
13/03/25, 17:30 - rohxn 03: Whoever attends should not miss a single day
13/03/25, 17:30 - rohxn 03: Thats what i guess they mentioned
13/03/25, 17:31 - Nishita ğŸª°: Idk they mentioned in the time table this subject
13/03/25, 17:32 - Nishita ğŸª°: It's better u ask Sailaja Ma'am once
13/03/25, 17:32 - Nishita ğŸª°: Message her so that we get a clarity
13/03/25, 17:43 - rohxn 03: <Media omitted>
13/03/25, 17:43 - rohxn 03: Ok
13/03/25, 17:44 - Wifeyâ¤ï¸: im scared ayyoooooooooooooo
13/03/25, 17:45 - Nishita ğŸª°: Me toooo
13/03/25, 17:45 - Nishita ğŸª°: This message was deleted
13/03/25, 17:46 - Nishita ğŸª°: Are you texting her ??
13/03/25, 17:49 - rohxn 03: ğŸ˜
13/03/25, 17:49 - rohxn 03: No this guy
13/03/25, 17:49 - rohxn 03: Edufyi
13/03/25, 17:49 - Wifeyâ¤ï¸: daaa
13/03/25, 17:50 - rohxn 03: If your performance and score is 78+ you will get
13/03/25, 17:50 - Wifeyâ¤ï¸: pick the call
13/03/25, 17:50 - rohxn 03: Haaa
13/03/25, 17:50 - rohxn 03: One more time
13/03/25, 17:50 - Nishita ğŸª°: What will you get ??
13/03/25, 17:50 - rohxn 03: Stipend
13/03/25, 20:51 - Nishita ğŸª°: Rohan
U received any msg ??
13/03/25, 21:14 - rohxn 03: Regarding what?
13/03/25, 21:15 - Nishita ğŸª°: Edufyi
13/03/25, 21:15 - rohxn 03: Nope
13/03/25, 21:16 - Nishita ğŸª°: Will they send mail or WhatsApp ??
13/03/25, 21:27 - rohxn 03: Absolute no idea!
14/03/25, 08:44 - rohxn 03: <Media omitted>
14/03/25, 08:45 - Wifeyâ¤ï¸: ğŸ˜³
14/03/25, 08:45 - Wifeyâ¤ï¸: When it is changed
14/03/25, 08:45 - Gass: Oh oh jolly jolly ğŸ¥³ğŸŒ
14/03/25, 08:45 - Gass: <Media omitted>
14/03/25, 08:45 - rohxn 03: Who knows
I just came to eat upma and saw this
14/03/25, 08:45 - Wifeyâ¤ï¸: Great enjoy enjoy
14/03/25, 08:46 - Gass: Do U know the reason ğŸ¤£ğŸ¤£ğŸ¤£
14/03/25, 08:46 - rohxn 03: Major told came here once and saw the food and made some changes
14/03/25, 08:46 - rohxn 03: Thats all i know
14/03/25, 08:46 - Gass: No no you are completely wrong ğŸ˜‚ğŸ˜‚
14/03/25, 08:47 - rohxn 03: Then??
14/03/25, 08:47 - Gass: When I was there in hostel fee was 1.13 lac
Now its 1.80 lacsğŸ˜‚ğŸ˜‚
14/03/25, 08:48 - Gass: Simple money speaks everywhere ğŸ’€ğŸŒ
14/03/25, 08:49 - rohxn 03: Oooooooooo
14/03/25, 08:49 - rohxn 03: Yes yes 22 k increased u know
14/03/25, 08:50 - rohxn 03: 1.55 lakh
14/03/25, 08:51 - Gass: No for new students its 1.80 lacs
14/03/25, 08:52 - rohxn 03: Its not same for everyone??
14/03/25, 08:52 - Gass: One of my friend told me
14/03/25, 08:52 - Gass: Obviously noğŸ˜‚ğŸ˜‚
14/03/25, 08:53 - Gass: Round of 70k hike
14/03/25, 08:54 - rohxn 03: ğŸ˜³ooooo
So its the money which talkedğŸ˜
14/03/25, 08:55 - Gass: Roughly 70,000 X 1000 students = 7,00,00,000 extra every year
14/03/25, 08:55 - Gass: What do you even need more than this ğŸ˜‚ğŸ˜‚ğŸ˜‚
14/03/25, 08:55 - Gass: Obviously yesğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‹
14/03/25, 08:56 - Gass: 1.8 lacs X 1000= 18,00,00,000ğŸŒ
14/03/25, 08:57 - Gass: And its rough there are more than 1000 students
14/03/25, 08:57 - Gass: They are saving more than 50% in this
14/03/25, 08:57 - Gass: And its called business ğŸ˜
14/03/25, 09:19 - rohxn 03: TrueğŸ¤ŒğŸ»
14/03/25, 09:20 - rohxn 03: @918799146002 Text him
The edufyi guy about the updates
14/03/25, 10:06 - rohxn 03: Edufyi Tech Solutions.vcf (file attached)
15/03/25, 16:42 - Wifeyâ¤ï¸: https://drive.google.com/drive/folders/126Q4qsWuXYU3rdCqp5ePu570A_F4HHsB?usp=sharing
15/03/25, 18:55 - rohxn 03: Nishitaaa one help
Did u run the full code??
15/03/25, 18:55 - rohxn 03: Exp 2
15/03/25, 20:13 - Nishita ğŸª°: Yes
15/03/25, 20:14 - Wifeyâ¤ï¸: Can u send the code and data set
15/03/25, 20:14 - Wifeyâ¤ï¸: code means ipynb file
15/03/25, 20:14 - Nishita ğŸª°: I already sent that in the zip file
15/03/25, 20:16 - Wifeyâ¤ï¸: is this??
15/03/25, 20:17 - Nishita ğŸª°: Yess
15/03/25, 20:17 - Nishita ğŸª°: This message was deleted
15/03/25, 20:17 - Nishita ğŸª°: This message was deleted
15/03/25, 21:35 - Wifeyâ¤ï¸: <Media omitted>
15/03/25, 21:35 - Wifeyâ¤ï¸: Updated exam timetable
15/03/25, 21:53 - rohxn 03: What is this minors 7 and 8
15/03/25, 21:53 - rohxn 03: Only one shit is there ryt
15/03/25, 21:56 - rohxn 03: You deleted this message
15/03/25, 21:56 - rohxn 03: You deleted this message
15/03/25, 21:58 - rohxn 03: <Media omitted>
15/03/25, 22:10 - Wifeyâ¤ï¸: ahh only one but they will divide ryt some teams in day 1 other teams on other day
15/03/25, 22:11 - rohxn 03: Oooh ok
15/03/25, 22:14 - Nishita ğŸª°: @916238330557 can you ask Sailaja Ma'am if there will be classes during cie 2
15/03/25, 22:28 - rohxn 03: I already asked a question 
She didnt replied
15/03/25, 22:31 - Nishita ğŸª°: Tmr may be she will
15/03/25, 22:38 - rohxn 03: Yeah
16/03/25, 09:33 - rohxn 03: People..... Have u done with the form???
16/03/25, 10:20 - Wifeyâ¤ï¸: Not yet
16/03/25, 10:35 - rohxn 03: Try to complete soon..... Today is the dead line
16/03/25, 19:19 - Wifeyâ¤ï¸: This message was deleted
16/03/25, 19:20 - Wifeyâ¤ï¸: This message was deleted
16/03/25, 19:20 - rohxn 03: C block it is
16/03/25, 19:20 - Gass: <Media omitted>
16/03/25, 19:20 - Wifeyâ¤ï¸: yes c block
16/03/25, 19:21 - Wifeyâ¤ï¸: nishita rohan Rohith  u ppl are in same room 403
16/03/25, 19:21 - rohxn 03: Shit.... So its a serious one
16/03/25, 19:21 - Wifeyâ¤ï¸: im in another room 402
16/03/25, 19:21 - Wifeyâ¤ï¸: daa
16/03/25, 19:21 - rohxn 03: Exam im talking about
16/03/25, 19:21 - Wifeyâ¤ï¸: haaa yes yes
16/03/25, 19:23 - Nishita ğŸª°: No I checked i am in different class
16/03/25, 19:24 - Nishita ğŸª°: Tmr is pe4 not pe3
16/03/25, 19:24 - Nishita ğŸª°: Check properly
16/03/25, 19:24 - rohxn 03: Which is this timetable
16/03/25, 19:24 - Nishita ğŸª°: Most probably pe3
16/03/25, 19:24 - Nishita ğŸª°: I think
16/03/25, 19:25 - Nishita ğŸª°: I mail they sent all the seating arrangements of every exam
16/03/25, 19:25 - rohxn 03: @919663957450 Edaaaa..... Chanagi noduğŸ˜†
16/03/25, 19:25 - Nishita ğŸª°: That's what ğŸ¤£
16/03/25, 19:25 - Nishita ğŸª°: Idk in which world she is
16/03/25, 19:25 - rohxn 03: If u can just sent the seating arrangement
16/03/25, 19:26 - Nishita ğŸª°: Logic u use how we 3 be in the same class having different electives
16/03/25, 19:26 - Nishita ğŸª°: Wait...........
16/03/25, 19:26 - Nishita ğŸª°: <Media omitted>
16/03/25, 19:29 - Wifeyâ¤ï¸: sorry
16/03/25, 19:29 - Wifeyâ¤ï¸: I didn't saw properly Im sorry
16/03/25, 19:29 - Wifeyâ¤ï¸: that was for pe3
16/03/25, 19:57 - rohxn 03: @919663957450 Dont forget to select cloud computing and data science as ur domain
17/03/25, 19:11 - rohxn 03: @919663957450 Have u filled the elective form?
17/03/25, 19:29 - Wifeyâ¤ï¸: yes
18/03/25, 20:27 - Wifeyâ¤ï¸: heyyy
18/03/25, 20:27 - Wifeyâ¤ï¸: <Media omitted>
18/03/25, 20:27 - Wifeyâ¤ï¸: this guy teaches toc
18/03/25, 20:28 - Wifeyâ¤ï¸: nishita and achu u remember
18/03/25, 21:12 - Nishita ğŸª°: Haan
18/03/25, 21:13 - Wifeyâ¤ï¸: see he is teaching toc
18/03/25, 21:13 - Wifeyâ¤ï¸: I cant belive
18/03/25, 21:13 - Nishita ğŸª°: Ade
18/03/25, 21:13 - Nishita ğŸª°: Thank God he is not the faculty
18/03/25, 21:14 - Wifeyâ¤ï¸: ufff
18/03/25, 21:14 - Wifeyâ¤ï¸: he has youtube channel and alll
18/03/25, 21:14 - Wifeyâ¤ï¸: and workin in college
18/03/25, 21:14 - Nishita ğŸª°: OMG ğŸ˜³
18/03/25, 21:16 - Wifeyâ¤ï¸: ğŸ¤¦ğŸ»â€â™€ï¸ayyo
18/03/25, 21:21 - Wifeyâ¤ï¸: hey
18/03/25, 21:21 - Wifeyâ¤ï¸: all fill the form
18/03/25, 21:21 - Wifeyâ¤ï¸: 10th and 12th percentage
18/03/25, 21:21 - Wifeyâ¤ï¸: he mailed again
18/03/25, 21:22 - Nishita ğŸª°: We don't have any other work right
18/03/25, 21:23 - Nishita ğŸª°: ğŸ¤¦â€â™€ï¸
18/03/25, 21:23 - Wifeyâ¤ï¸: That's what
18/03/25, 21:26 - Nishita ğŸª°: Where is he ?? He is not online I think
18/03/25, 21:27 - Wifeyâ¤ï¸: YES
18/03/25, 22:20 - rohxn 03: ğŸ˜³ğŸ˜³
18/03/25, 22:20 - rohxn 03: This guy has a yt channel??
18/03/25, 22:20 - Wifeyâ¤ï¸: Yes
18/03/25, 22:21 - rohxn 03: With 6 lakh subscribersaaağŸ˜³
18/03/25, 22:21 - Wifeyâ¤ï¸: He came to invigilate for us today
18/03/25, 22:21 - Wifeyâ¤ï¸: Ufff
18/03/25, 22:21 - Wifeyâ¤ï¸: And working in rv college
18/03/25, 22:21 - rohxn 03: Ur bestie.... I knowğŸ˜
18/03/25, 22:21 - rohxn 03: AtgeğŸ¤ŒğŸ»
18/03/25, 22:21 - Wifeyâ¤ï¸: Chee
18/03/25, 22:22 - Wifeyâ¤ï¸: Ufff money rain ide avanhatra
18/03/25, 22:22 - rohxn 03: ğŸ˜†truee
19/03/25, 15:55 - Nishita ğŸª°: <Media omitted>
19/03/25, 16:39 - rohxn 03: Athul doesnt know any other than annapurnağŸ˜Š

I told u
19/03/25, 16:40 - Wifeyâ¤ï¸: Howda bere??
19/03/25, 18:31 - rohxn 03: What did shailaja maam told
19/03/25, 18:32 - Nishita ğŸª°: You woke up
19/03/25, 18:32 - rohxn 03: Haaa
19/03/25, 18:32 - rohxn 03: Now
19/03/25, 18:32 - Nishita ğŸª°: How many times we should call you
19/03/25, 18:32 - Nishita ğŸª°: Wait I will call you
19/03/25, 18:32 - rohxn 03: Nope
19/03/25, 18:32 - rohxn 03: Not now
19/03/25, 18:32 - rohxn 03: Ill call later
19/03/25, 18:33 - Nishita ğŸª°: It is imp
19/03/25, 18:33 - Nishita ğŸª°: If you want to know about Guna bcoz she cant call now or msg you
19/03/25, 18:34 - Nishita ğŸª°: Neither me
19/03/25, 18:34 - rohxn 03: Know about her??
19/03/25, 18:34 - rohxn 03: Where u ppl are
19/03/25, 18:34 - rohxn 03: Lemme reach my room
19/03/25, 18:34 - Nishita ğŸª°: We left clg at 5:45
19/03/25, 18:34 - Nishita ğŸª°: Where are you ??
19/03/25, 18:36 - rohxn 03: Going to my room
19/03/25, 18:54 - Nishita ğŸª°: https://chat.whatsapp.com/IaTxOUcfWFBLIFQ53FHgxv
19/03/25, 21:59 - rohxn 03: Tell tell
19/03/25, 22:00 - Nishita ğŸª°: Haan
19/03/25, 22:00 - Nishita ğŸª°: Tmr are you guys coming ??
19/03/25, 22:02 - rohxn 03: <Media omitted>
19/03/25, 22:05 - Nishita ğŸª°: That's ok
19/03/25, 22:06 - Nishita ğŸª°: But tmr are you coming as we have placement training and they sent some mail with qr code
19/03/25, 22:06 - Nishita ğŸª°: Then maybe it's imp
19/03/25, 22:07 - Nishita ğŸª°: And one more thing we have to register for the workshop
19/03/25, 22:07 - Nishita ğŸª°: Form we need to fill
19/03/25, 22:09 - Wifeyâ¤ï¸: can u send the register form or link whatever
19/03/25, 22:10 - Nishita ğŸª°: Link is not there we have to directly click and it opens
19/03/25, 22:27 - rohxn 03: Our programme will be over by 1 or 1 30
19/03/25, 22:27 - rohxn 03: No worries
19/03/25, 22:27 - rohxn 03: Tomorrow we can do that ryt?
19/03/25, 22:27 - Nishita ğŸª°: Ok
19/03/25, 22:27 - Nishita ğŸª°: Yes
19/03/25, 22:40 - Wifeyâ¤ï¸: IM GOING TO REGISTER OK
19/03/25, 22:40 - Wifeyâ¤ï¸: MINE AND ACHU URS
19/03/25, 22:40 - Wifeyâ¤ï¸: NISHITA DID U REGISTER
19/03/25, 22:40 - rohxn 03: Why ur shoutingğŸ¤¨
19/03/25, 22:40 - Wifeyâ¤ï¸: eeeee
19/03/25, 22:40 - Wifeyâ¤ï¸: u r not in insta wt r u f=doing here
19/03/25, 22:40 - Nishita ğŸª°: No
19/03/25, 22:40 - Wifeyâ¤ï¸: y
19/03/25, 22:40 - Wifeyâ¤ï¸: when we will submot
19/03/25, 22:41 - Nishita ğŸª°: He said we will do tmr
19/03/25, 22:41 - Nishita ğŸª°: So
19/03/25, 22:41 - Wifeyâ¤ï¸: someone should remind
19/03/25, 22:41 - Wifeyâ¤ï¸: w=if we forget we don't know
19/03/25, 22:41 - Wifeyâ¤ï¸: and keep remainder in phones
19/03/25, 22:42 - Wifeyâ¤ï¸: eeeee
19/03/25, 22:42 - Wifeyâ¤ï¸: just for our good eeeeeeee
19/03/25, 22:43 - rohxn 03: ğŸ˜­ğŸ˜­
19/03/25, 22:45 - Wifeyâ¤ï¸: Poda patti <This message was edited>
19/03/25, 22:45 - Nishita ğŸª°: What happened to her ??
19/03/25, 22:45 - Nishita ğŸª°: She is gonna mad
19/03/25, 22:45 - Wifeyâ¤ï¸: Ah if all forget na then we will understand
19/03/25, 22:46 - Nishita ğŸª°: Karme ve ğŸ¤¦â€â™€ï¸
19/03/25, 22:47 - Gass: English murderd successfully â˜ ï¸ğŸ˜
19/03/25, 22:47 - Wifeyâ¤ï¸: Yes
19/03/25, 22:48 - rohxn 03: U tooğŸ˜†
19/03/25, 22:48 - Wifeyâ¤ï¸: I did that
19/03/25, 22:48 - Wifeyâ¤ï¸: ğŸ˜
19/03/25, 22:48 - rohxn 03: ğŸ¤¨
19/03/25, 22:48 - Wifeyâ¤ï¸: Eeee
19/03/25, 22:48 - rohxn 03: Why my emoji isnt live
19/03/25, 22:48 - rohxn 03: ğŸ˜‰
19/03/25, 22:48 - Gass: I do it wantedly
19/03/25, 22:48 - rohxn 03: Haa yass
19/03/25, 22:48 - Gass: We are vatal nagraj fansğŸ˜ğŸ˜‚
19/03/25, 22:49 - Wifeyâ¤ï¸: Rohith they don't know who is he
19/03/25, 22:49 - Gass: No problem let them do a research on him ğŸ˜’
19/03/25, 22:50 - Wifeyâ¤ï¸: ğŸ˜†
19/03/25, 22:50 - Gass: He is the man who made our school days betterğŸ™
20/03/25, 13:10 - Wifeyâ¤ï¸: @918799146002 bvc elli idyaaa
20/03/25, 13:13 - Nishita ğŸª°: Pg
20/03/25, 13:13 - Nishita ğŸª°: I didn't come to clg today
20/03/25, 13:18 - rohxn 03: U will not come to Meeting also
20/03/25, 13:19 - rohxn 03: Nishita
20/03/25, 15:43 - Nishita ğŸª°: Glassdoor website for placement drive
22/03/25, 17:43 - rohxn 03: <Media omitted>
22/03/25, 17:43 - rohxn 03: <Media omitted>
22/03/25, 17:44 - rohxn 03: @916364562073 Edaaa ur cie submission ok
22/03/25, 17:44 - rohxn 03: U can submit from ur phone no worries
22/03/25, 17:45 - Nishita ğŸª°: @916238330557 can you send your photos if possible?? I wanted to see
22/03/25, 17:45 - rohxn 03: <Media omitted>
22/03/25, 17:45 - rohxn 03: This one
22/03/25, 17:46 - Nishita ğŸª°: Only one ??
22/03/25, 17:46 - rohxn 03: Other one lemme seee
22/03/25, 17:46 - Nishita ğŸª°: Ok
22/03/25, 17:47 - rohxn 03: <Media omitted>
22/03/25, 17:47 - rohxn 03: <Media omitted>
22/03/25, 17:47 - rohxn 03: <Media omitted>
22/03/25, 17:47 - rohxn 03: <Media omitted>
22/03/25, 17:47 - Wifeyâ¤ï¸: â¤â¤
22/03/25, 17:48 - Wifeyâ¤ï¸: Sooo good
22/03/25, 17:48 - rohxn 03: ğŸ˜ğŸ˜ğŸ˜
22/03/25, 17:48 - Nishita ğŸª°: So nice these pics are
22/03/25, 17:48 - Wifeyâ¤ï¸: Thumbaaa chanagide
22/03/25, 17:48 - Nishita ğŸª°: Good work ğŸ¥°
22/03/25, 17:48 - rohxn 03: Nobody bring the props u know......
I took a some dry leaves and took some branches from treesğŸ¤¦ğŸ»â€â™‚ï¸
22/03/25, 17:49 - Wifeyâ¤ï¸: Ahhh great work chuğŸ¥°
22/03/25, 17:49 - rohxn 03: Denkyu
22/03/25, 17:49 - Nishita ğŸª°: See hardwork pays u
22/03/25, 17:49 - Wifeyâ¤ï¸: ğŸ¥°
22/03/25, 17:49 - Nishita ğŸª°: ğŸ¥°
22/03/25, 17:50 - Nishita ğŸª°: @916238330557 say thanks to me also. I also appreciated your work bvc
22/03/25, 17:51 - rohxn 03: Ayyooo sorry..... Denkyuuuuuuuuu
22/03/25, 17:52 - Nishita ğŸª°: Ahh okk
22/03/25, 21:07 - rohxn 03: @916364562073 Edaa naale we r going to an ngo
6am can u join
22/03/25, 21:09 - Gass: No da i told you na i have myself arranged a function a Tommorow on occasion of my parents 25th year anniversary
22/03/25, 21:32 - Nishita ğŸª°: @916238330557 @919663957450 
What all are things we need to bring for tomorrow's task :
1. Mask
2. Gloves
3. Water bottle 
4. Cap
5. Passport size 2 photos
6. College ID card 
7. Printout of two forms if you can get
8. 200 rupees for registration 
9. Umbrella
22/03/25, 21:32 - Nishita ğŸª°: <Media omitted>
22/03/25, 21:32 - Nishita ğŸª°: <Media omitted>
22/03/25, 21:33 - Nishita ğŸª°: My junior we need these printouts
22/03/25, 21:33 - Wifeyâ¤ï¸: Printouts doubt
22/03/25, 21:33 - Wifeyâ¤ï¸: Who will open that early
22/03/25, 21:33 - Nishita ğŸª°: Ade
22/03/25, 21:33 - Nishita ğŸª°: Let's see
22/03/25, 21:34 - Wifeyâ¤ï¸: Ok
22/03/25, 21:34 - Wifeyâ¤ï¸: Now go all sleep
22/03/25, 21:34 - Nishita ğŸª°: Where is he ?? He didn't see the msg
22/03/25, 21:34 - Wifeyâ¤ï¸: Haa he will see no worries
22/03/25, 21:35 - Nishita ğŸª°: Haan okk
22/03/25, 21:35 - Nishita ğŸª°: Check everything once before leaving
22/03/25, 21:35 - Wifeyâ¤ï¸: Wokey <This message was edited>
22/03/25, 21:36 - Nishita ğŸª°: Ok then
22/03/25, 21:36 - Nishita ğŸª°: Good night ğŸ˜´
22/03/25, 21:36 - Nishita ğŸª°: @919663957450 don't forget to call us in the morning
22/03/25, 21:36 - Wifeyâ¤ï¸: Good night
22/03/25, 21:36 - Wifeyâ¤ï¸: Sure I'll
22/03/25, 21:36 - Wifeyâ¤ï¸: KEEP YOUR RINGTONE MAX VOLUME
22/03/25, 21:36 - Nishita ğŸª°: Tata ğŸ‘‹ğŸ‘‹ğŸ‘‹ğŸ‘‹
22/03/25, 21:37 - Nishita ğŸª°: Okkk
22/03/25, 21:37 - Wifeyâ¤ï¸: Okok
22/03/25, 21:37 - rohxn 03: Oooooo
22/03/25, 21:38 - rohxn 03: Nanna call maadu yellaaaru
22/03/25, 21:38 - rohxn 03: Mmaaaaaa
22/03/25, 21:38 - Wifeyâ¤ï¸: Ahhh ahhh
22/03/25, 21:38 - Wifeyâ¤ï¸: Read this carefully
22/03/25, 21:38 - rohxn 03: ğŸ˜ğŸ˜
22/03/25, 21:45 - Gass: Banni yalarau
22/03/25, 21:45 - Gass: Yalaru*
22/03/25, 21:45 - Gass: After ngo work
22/03/25, 21:46 - Gass: Which place are you ppl going
23/03/25, 05:02 - rohxn 03: Did everyone woke!!
23/03/25, 05:03 - Nishita ğŸª°: I woke
23/03/25, 05:08 - rohxn 03: Nishita bring sunscreen if u have one for u
23/03/25, 05:09 - Gass: <Media omitted>
23/03/25, 05:09 - rohxn 03: U woke
23/03/25, 05:09 - Gass: I should go to the market ğŸ™‚
23/03/25, 05:10 - rohxn 03: ğŸ˜³ for what
23/03/25, 05:10 - rohxn 03: Reason
23/03/25, 05:10 - Gass: For fresh vegetables and items
23/03/25, 05:10 - Gass: I told na myre i have arranged a function today
23/03/25, 05:10 - Gass: For cooking we should bring things na
23/03/25, 05:11 - Gass: If we go early in the morning we will get everything fresh aduke i woke early
23/03/25, 05:15 - rohxn 03: Oooh yass yass
23/03/25, 05:16 - Gass: Haa
23/03/25, 05:18 - Gass: Where are you going today?
23/03/25, 05:18 - Gass: Which area?
23/03/25, 05:32 - rohxn 03: @918799146002 Leave at 5 35 to 5 40 ok
23/03/25, 05:32 - rohxn 03: Place they only knows
I dont remember
23/03/25, 05:39 - Wifeyâ¤ï¸: I'm the 1st
23/03/25, 05:39 - rohxn 03: Kindi i woke before u idiot
23/03/25, 05:40 - rohxn 03: Ee bvc elli idhe?
23/03/25, 05:40 - rohxn 03: I left the hostel
@918799146002
23/03/25, 05:41 - Wifeyâ¤ï¸: Poda patti
23/03/25, 05:41 - rohxn 03: Where r u madam
23/03/25, 05:42 - Wifeyâ¤ï¸: I'm still in home
23/03/25, 05:42 - Wifeyâ¤ï¸: I'm ready okay
23/03/25, 05:42 - rohxn 03: Fine fine
23/03/25, 05:42 - Wifeyâ¤ï¸: Red tshirt
23/03/25, 05:42 - Wifeyâ¤ï¸: Black pant
23/03/25, 05:42 - rohxn 03: Green and black
23/03/25, 05:42 - Wifeyâ¤ï¸: Pink hoodie
23/03/25, 05:42 - Wifeyâ¤ï¸: U?
23/03/25, 05:42 - rohxn 03: Haa
23/03/25, 05:42 - Wifeyâ¤ï¸: Good good
23/03/25, 05:42 - Wifeyâ¤ï¸: Insta alli come
23/03/25, 05:43 - Wifeyâ¤ï¸: I'm leaving
23/03/25, 05:43 - rohxn 03: Heyy ivagayaaa
23/03/25, 05:44 - rohxn 03: Avalu innu bandillaa
23/03/25, 05:44 - Wifeyâ¤ï¸: Call
23/03/25, 05:44 - Wifeyâ¤ï¸: We have to catch 3 bus
23/03/25, 05:44 - rohxn 03: ğŸ¤¨
23/03/25, 05:44 - rohxn 03: Naan en maadli ee bvc bandillaa innu
23/03/25, 05:44 - Gass: Guna yav area hogtha irodu
23/03/25, 05:46 - Wifeyâ¤ï¸: Kumarswamy layout
23/03/25, 05:46 - Gass: Okay ok
23/03/25, 05:50 - Nishita ğŸª°: @916238330557 I have left 5 mins back
23/03/25, 05:50 - Nishita ğŸª°: I am near Pornima Palace
23/03/25, 05:51 - rohxn 03: Im in that bus stop
23/03/25, 05:51 - Wifeyâ¤ï¸: Ppl
23/03/25, 05:51 - Nishita ğŸª°: Haan coming
23/03/25, 05:51 - Wifeyâ¤ï¸: I successfully forgot
23/03/25, 05:51 - Wifeyâ¤ï¸: One thing
23/03/25, 05:51 - rohxn 03: What
23/03/25, 05:51 - Wifeyâ¤ï¸: UmbrellağŸ˜
23/03/25, 05:51 - rohxn 03: I have
23/03/25, 05:52 - Wifeyâ¤ï¸: Okay share okğŸ˜ğŸ˜
23/03/25, 05:52 - rohxn 03: ğŸ˜ˆsure
23/03/25, 05:52 - Wifeyâ¤ï¸: ğŸ˜
23/03/25, 05:53 - rohxn 03: Dont chat im bike ammu
23/03/25, 05:53 - rohxn 03: On
23/03/25, 05:53 - Wifeyâ¤ï¸: Car
23/03/25, 05:53 - Wifeyâ¤ï¸: Dear
23/03/25, 05:53 - Wifeyâ¤ï¸: ğŸ˜
23/03/25, 05:53 - Wifeyâ¤ï¸: I'm in quarters
23/03/25, 05:56 - rohxn 03: Txt when u reach njanabharathi
23/03/25, 05:56 - Wifeyâ¤ï¸: Sure
23/03/25, 05:56 - Wifeyâ¤ï¸: Did u took ur passport size pic
23/03/25, 05:57 - Wifeyâ¤ï¸: Hey I reached okay
23/03/25, 05:57 - rohxn 03: ğŸ˜‰yep
23/03/25, 05:58 - rohxn 03: Ammu we got bus
23/03/25, 05:58 - rohxn 03: KA 57 F 6546
23/03/25, 16:13 - Wifeyâ¤ï¸: null
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: null
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 16:13 - Wifeyâ¤ï¸: <Media omitted>
23/03/25, 17:53 - Nishita ğŸª°: Hey guys
23/03/25, 17:53 - Nishita ğŸª°: Keep your certificates safe we need them in future
23/03/25, 21:43 - Nishita ğŸª°: https://unity.com/download
23/03/25, 21:44 - Nishita ğŸª°: https://unity.com/releases/editor/archive : 2021.3.49f1
23/03/25, 21:45 - Nishita ğŸª°: Download this can come tmr for workshop
23/03/25, 21:45 - Nishita ğŸª°: IMP ğŸ‘†
24/03/25, 09:00 - Wifeyâ¤ï¸: hey I cant see anything in his link
24/03/25, 09:01 - Wifeyâ¤ï¸: its showing 404 not found......
24/03/25, 13:46 - Wifeyâ¤ï¸: They are telling to take group photo
24/03/25, 13:46 - Wifeyâ¤ï¸: Nishita and achu
24/03/25, 13:46 - rohxn 03: When?
24/03/25, 13:46 - Nishita ğŸª°: Haan
24/03/25, 13:46 - Wifeyâ¤ï¸: Now right now
24/03/25, 13:46 - Nishita ğŸª°: Ok
24/03/25, 13:46 - rohxn 03: 2 i clock saakaaa
24/03/25, 13:47 - rohxn 03: Im downloading adke
24/03/25, 13:47 - Nishita ğŸª°: I am coming
24/03/25, 13:47 - Wifeyâ¤ï¸: <Media omitted>
24/03/25, 13:47 - rohxn 03: Shit
24/03/25, 13:47 - rohxn 03: Where is this class
24/03/25, 13:47 - Nishita ğŸª°: But it will take 5 mins
24/03/25, 13:47 - rohxn 03: .....
24/03/25, 13:47 - Nishita ğŸª°: B block
24/03/25, 13:47 - rohxn 03: In b block where
24/03/25, 13:48 - rohxn 03: Oooo near vending machine ryt
24/03/25, 13:48 - Wifeyâ¤ï¸: Jon
24/03/25, 13:48 - Wifeyâ¤ï¸: Join
24/03/25, 13:48 - Wifeyâ¤ï¸: Vending machine
24/03/25, 13:48 - Wifeyâ¤ï¸: B block
24/03/25, 13:49 - Wifeyâ¤ï¸: Finished
24/03/25, 13:49 - Nishita ğŸª°: Haan
24/03/25, 13:49 - Nishita ğŸª°: It's ok
24/03/25, 13:49 - Wifeyâ¤ï¸: It's just a group photo needed  anthaa vidit told
24/03/25, 13:49 - Nishita ğŸª°: Fine
24/03/25, 13:50 - Nishita ğŸª°: Now come to a005
24/03/25, 13:55 - rohxn 03: Pls let me know when teacher enters the class
24/03/25, 13:56 - Wifeyâ¤ï¸: Ok
24/03/25, 14:00 - rohxn 03: @918799146002 is it downloading fast??
24/03/25, 17:04 - rohxn 03: <Media omitted>
24/03/25, 17:04 - rohxn 03: Nishita we got the certificate ok
24/03/25, 17:11 - Gass: Did they pay you ğŸ‘€ğŸ˜‚
24/03/25, 17:11 - Gass: How much did you score?
24/03/25, 17:18 - Nishita ğŸª°: From u got ??
24/03/25, 17:18 - Nishita ğŸª°: How to do that ??
24/03/25, 17:32 - Wifeyâ¤ï¸: Near ur pg printing shop will be there, if not naale baa here xerox shop is there right, or universitys also fine
But opposite xerox is better because all equipments are there

Come there and ask that bayya for wipro dice app
He will tell he don't know
Then do a sexy belly dance in front of him 


Simple
24/03/25, 17:33 - Nishita ğŸª°: Rohan stop ğŸ˜¡
24/03/25, 17:33 - Nishita ğŸª°: Don't irritate me
24/03/25, 17:33 - Gass: <Media omitted>
24/03/25, 17:34 - Wifeyâ¤ï¸: ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£
24/03/25, 17:35 - Gass: <Media omitted>
24/03/25, 17:39 - Nishita ğŸª°: @919663957450 I will call you later
24/03/25, 17:40 - Wifeyâ¤ï¸: Ok....
24/03/25, 18:36 - Wifeyâ¤ï¸: <Media omitted>
24/03/25, 18:38 - Nishita ğŸª°: I got ğŸ‘†
24/03/25, 18:38 - Nishita ğŸª°: She had downloaded that in her phone
24/03/25, 18:38 - Nishita ğŸª°: Thank God ğŸ™
24/03/25, 19:31 - Wifeyâ¤ï¸: All credits goes to meğŸ˜
24/03/25, 19:37 - rohxn 03: <Media omitted>
25/03/25, 16:46 - Wifeyâ¤ï¸: null
25/03/25, 16:46 - Wifeyâ¤ï¸: <Media omitted>
25/03/25, 16:46 - Wifeyâ¤ï¸: <Media omitted>
25/03/25, 16:46 - Wifeyâ¤ï¸: <Media omitted>
25/03/25, 16:46 - Wifeyâ¤ï¸: <Media omitted>
25/03/25, 20:38 - rohxn 03: <Media omitted>
25/03/25, 20:38 - Nishita ğŸª°: Where are you bvc ??
25/03/25, 20:39 - Nishita ğŸª°: U went alone?? When ?
25/03/25, 20:39 - Wifeyâ¤ï¸: seriously achu
25/03/25, 20:39 - Wifeyâ¤ï¸: alla r u seriou
25/03/25, 20:40 - Wifeyâ¤ï¸: one second atleast one sec nin wife remember agilavaa??
25/03/25, 20:41 - rohxn 03: Aaythu ammu
So i bought 2 plates
One is....ğŸ˜”

One plate is for uğŸ¤§
25/03/25, 20:45 - Gass: What is that myre?
25/03/25, 20:45 - Gass: Nale class thago
Tax akkuğŸ˜‚ğŸ¤£
25/03/25, 20:48 - Wifeyâ¤ï¸: Haa
25/03/25, 20:55 - Gass: <Media omitted>
25/03/25, 21:00 - Wifeyâ¤ï¸: ğŸ™„
25/03/25, 21:03 - Gass: Online delivery madbeku
25/03/25, 21:03 - Gass: Ninne thindbitu one for you anthe ğŸ˜’
25/03/25, 21:04 - Wifeyâ¤ï¸: Hogli bidu thinli
25/03/25, 21:04 - Gass: Ella Ella bekke beku nyaya beku
25/03/25, 21:05 - Gass: Vatal nagraj karsana yemme mele savari madsona
25/03/25, 21:05 - rohxn 03: Myre dont put ideas in her head
25/03/25, 21:05 - Gass: ğŸ¤£ğŸ¤£ğŸ¤£
25/03/25, 21:06 - Gass: Scissors for your pocket âœ‚ï¸ğŸ˜‚
25/03/25, 21:06 - rohxn 03: ğŸ˜­ğŸ˜­
25/03/25, 21:06 - Gass: ğŸ˜‚ğŸ˜‚ğŸ˜‚
26/03/25, 15:35 - Gass: They told me not to give to anyone
26/03/25, 15:35 - Gass: Options note madkoli
26/03/25, 15:35 - Gass: Don't tell anyone
26/03/25, 15:35 - Wifeyâ¤ï¸: Haaa send madu pa
26/03/25, 15:35 - Gass: Paper no dout same for everyone
26/03/25, 15:35 - Gass: <Media omitted>
26/03/25, 15:35 - Wifeyâ¤ï¸: Ok
26/03/25, 21:37 - Gass: https://forms.gle/DMhEmGonFcG8miPr9
26/03/25, 21:37 - Gass: ARS01
26/03/25, 21:37 - Gass: Guys e form yest jana agutho avr athra fill madsi
26/03/25, 21:37 - Gass: This message was deleted
26/03/25, 21:38 - Gass: With this referral code
29/03/25, 22:02 - Nishita ğŸª°: <Media omitted>
29/03/25, 22:02 - Nishita ğŸª°: <Media omitted>
29/03/25, 22:03 - Nishita ğŸª°: Guna if possible bring both form printouts
29/03/25, 22:20 - Wifeyâ¤ï¸: okayy
31/03/25, 09:37 - rohxn 03: Heyyy
31/03/25, 09:37 - rohxn 03: I got letter from srinivasan ngo
31/03/25, 09:37 - rohxn 03: Whats next??
31/03/25, 09:54 - Nishita ğŸª°: Feedback form
31/03/25, 09:58 - Wifeyâ¤ï¸: I didn't got any
31/03/25, 09:58 - Wifeyâ¤ï¸: Got in whatsApp
31/03/25, 09:58 - Wifeyâ¤ï¸: ğŸ˜
31/03/25, 09:59 - Nishita ğŸª°: Did Sir say anything about feedback form ??
31/03/25, 09:59 - Wifeyâ¤ï¸: Hey help me what should I reply back
31/03/25, 09:59 - Wifeyâ¤ï¸: <Media omitted>
31/03/25, 10:00 - Wifeyâ¤ï¸: What should I replyğŸ˜­ğŸ˜­
31/03/25, 10:00 - Wifeyâ¤ï¸: Papaa we gave him lot work
31/03/25, 10:00 - Nishita ğŸª°: Say Thanks to him
31/03/25, 10:00 - Wifeyâ¤ï¸: That's it
31/03/25, 10:00 - Nishita ğŸª°: What else will you write ??
31/03/25, 10:01 - Wifeyâ¤ï¸: Nothing I thought to say sorry
31/03/25, 10:01 - Wifeyâ¤ï¸: Because he mentioned ryt only for us he wrote the letter
31/03/25, 10:01 - Nishita ğŸª°: Ok mention it then
31/03/25, 10:02 - Wifeyâ¤ï¸: Haa
31/03/25, 10:04 - Nishita ğŸª°: He didn't say anything about the feedback form ??
31/03/25, 10:04 - Wifeyâ¤ï¸: Nope
31/03/25, 10:04 - Nishita ğŸª°: What to do then ??
31/03/25, 10:05 - Wifeyâ¤ï¸: That achu want to ask astee
31/03/25, 10:05 - Wifeyâ¤ï¸: I can't ask again
31/03/25, 10:05 - Wifeyâ¤ï¸: How much we txted
31/03/25, 10:05 - Wifeyâ¤ï¸: I felt like we gave him lot of work
31/03/25, 10:05 - Wifeyâ¤ï¸: Because only for us he wrote a letter
31/03/25, 10:06 - Nishita ğŸª°: Ade
31/03/25, 10:06 - Nishita ğŸª°: Call him and tell him to text him or call him
31/03/25, 10:06 - Wifeyâ¤ï¸: Call he better I guess
31/03/25, 10:07 - Wifeyâ¤ï¸: It's okay now achu's turn
31/03/25, 10:07 - Wifeyâ¤ï¸: Let him call and ask about the feedback form <This message was edited>
31/03/25, 10:07 - Nishita ğŸª°: Understood
31/03/25, 10:09 - Nishita ğŸª°: U call that bvc and tell do this task
31/03/25, 10:09 - Wifeyâ¤ï¸: I'm txting he saw
31/03/25, 10:10 - Wifeyâ¤ï¸: Oh u r talking to someone shoreeeğŸ˜
31/03/25, 10:11 - Nishita ğŸª°: Hmmm
31/03/25, 10:57 - rohxn 03: <Media omitted>
31/03/25, 11:00 - Gass: Guys has anyone of you completed the constitution of India assignment
31/03/25, 11:20 - Nishita ğŸª°: Don't use my dialogue on me only ğŸ‘¿
31/03/25, 12:51 - rohxn 03: U can't submit edaaaa
31/03/25, 12:51 - rohxn 03: Date mukithu
31/03/25, 13:12 - Gass: Ay i can
31/03/25, 13:12 - Gass: They have given time till today 5pm
31/03/25, 13:13 - Gass: Send madu myre
31/03/25, 13:15 - rohxn 03: Hey srinivasan sir told he done anthaa
@918799146002 @919663957450
31/03/25, 13:15 - rohxn 03: I don't have my lap kuttaaa
Im in home
31/03/25, 13:15 - Gass: Ok what about Guna
31/03/25, 13:16 - Gass: Guna idre kalsamma submit madbidtini
01/04/25, 13:02 - rohxn 03: U got????
01/04/25, 13:03 - rohxn 03: Hey ppl today we need to  submit the report ryt???
01/04/25, 13:03 - rohxn 03: What and all to do......
01/04/25, 13:03 - rohxn 03: Ammu... Help me ok.... I dont have lap illi
01/04/25, 21:46 - rohxn 03: Put up Volunteer Painter
01/04/25, 21:46 - rohxn 03: This is what vidith told
01/04/25, 21:50 - Nishita ğŸª°: Use this if till 1/2 hour we don't get msg from the NGO person
01/04/25, 21:52 - rohxn 03: Ok..... Ammu put that report in our GCR and wait for half an hour
If no updates from his side..... We'll turn

What u ppl say!
01/04/25, 21:53 - Wifeyâ¤ï¸: fine
01/04/25, 21:54 - Wifeyâ¤ï¸: ill just add like this 

role assigned: volunteer painter
01/04/25, 22:19 - rohxn 03: Heyyy
01/04/25, 22:19 - rohxn 03: No updates
01/04/25, 22:19 - rohxn 03: Shall we turn
01/04/25, 22:20 - Wifeyâ¤ï¸: ookayy
01/04/25, 22:21 - Nishita ğŸª°: Okk
01/04/25, 22:22 - Wifeyâ¤ï¸: then im going to subit
02/04/25, 15:45 - Wifeyâ¤ï¸: nishitaa and achu u both got 48 out of 50
02/04/25, 16:51 - Nishita ğŸª°: U ???
02/04/25, 17:51 - rohxn 03: ğŸ¤¨ğŸ¤¨
02/04/25, 17:51 - rohxn 03: On what
02/04/25, 17:51 - Wifeyâ¤ï¸: Constitution of india
02/04/25, 17:52 - rohxn 03: U
02/04/25, 17:52 - Wifeyâ¤ï¸: I got 46ğŸ™‚
02/04/25, 17:52 - rohxn 03: Haavu
02/04/25, 17:53 - Gass: U haavu nağŸ˜‚ğŸğŸ
02/04/25, 17:53 - rohxn 03: ğŸ˜­ğŸ˜­
03/04/25, 08:50 - rohxn 03: @918799146002 Bring phone charger if u can
03/04/25, 09:27 - Nishita ğŸª°: I saw the msg
Actually they stopped me at the shortcut gate
I came late bcoz of that
04/04/25, 14:57 - Nishita ğŸª°: https://www.kaggle.com/code/mohammedabdeldayem/facial-expression-recognition-using-vit
@916238330557 FOR YOUR REFERENCE
04/04/25, 16:02 - rohxn 03: ğŸ‘
04/04/25, 17:34 - Nishita ğŸª° pinned a message
04/04/25, 20:38 - rohxn 03: Ppl u done the payment?
04/04/25, 21:10 - Wifeyâ¤ï¸: Hey I didn't fill the form
04/04/25, 21:10 - Wifeyâ¤ï¸: Can I do it tomorrow
04/04/25, 21:42 - Nishita ğŸª°: Even I didn't
04/04/25, 21:42 - Nishita ğŸª°: I was asking my parents about that
05/04/25, 13:40 - Nishita ğŸª°: https://meet.google.com/mod-wvym-hvg
05/04/25, 13:40 - Nishita ğŸª°: @916238330557 @919663957450  Join now
05/04/25, 13:59 - Wifeyâ¤ï¸: join
05/04/25, 13:59 - Wifeyâ¤ï¸: join
05/04/25, 14:03 - Wifeyâ¤ï¸: Anik Acharjee <anika@rvu.edu.in>
05/04/25, 14:04 - Wifeyâ¤ï¸: muralidharb@rvu.edu.in
05/04/25, 14:04 - Wifeyâ¤ï¸: Muralidhar Billa
05/04/25, 15:25 - Nishita ğŸª°: @919663957450 and @916238330557 we will have a conference call in the evening
05/04/25, 15:46 - Wifeyâ¤ï¸: <Media omitted>
05/04/25, 16:07 - Nishita ğŸª°: U went there ??
05/04/25, 16:07 - Nishita ğŸª°: Without me ğŸ’”
05/04/25, 16:19 - Wifeyâ¤ï¸: We called u bvc, u told ur security won't leave u inside
05/04/25, 16:20 - Nishita ğŸª°: I thought you will go to canteen
05/04/25, 16:20 - Nishita ğŸª°: I would have come from other side of road
05/04/25, 16:20 - Wifeyâ¤ï¸: We also thought, alli enu illaa saturday ryt
05/04/25, 16:21 - Wifeyâ¤ï¸: Oooooh....... Next time be in class dont run to pg
05/04/25, 16:21 - Nishita ğŸª°: It's ok bidu
We will go next time
05/04/25, 16:21 - Nishita ğŸª°: I was tired da
05/04/25, 19:28 - rohxn 03: Naale ngo illaaaa
Be happyğŸ˜Š
05/04/25, 19:28 - rohxn 03: I called him
05/04/25, 19:28 - rohxn 03: Next week ide
05/04/25, 19:47 - Nishita ğŸª°: Okk
05/04/25, 19:47 - Nishita ğŸª°: Atleast complete the coding part of our mla project @916238330557
06/04/25, 10:56 - rohxn 03: <Media omitted>
06/04/25, 10:56 - rohxn 03: Ppl.....This is puttu by the way
06/04/25, 10:56 - rohxn 03: Who never saw this
06/04/25, 10:57 - Nishita ğŸª°: I know this ğŸ‘
06/04/25, 18:40 - Wifeyâ¤ï¸: <Media omitted>
06/04/25, 18:40 - Wifeyâ¤ï¸: <Media omitted>
06/04/25, 18:40 - Wifeyâ¤ï¸: This too ok!
06/04/25, 19:09 - Nishita ğŸª°: import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,classification_report,f1_score  
import cv2
import os
import torch
import seaborn as sns
from sklearn.model_selection import train_test_split
from datasets import load_dataset,load_metric,concatenate_datasets
from huggingface_hub import notebook_login
from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer, pipeline
from torchvision.transforms import (  # Import image transformation functions
    CenterCrop,  # Center crop an image
    Compose,  # Compose multiple image transformations
    Normalize,  # Normalize image pixel values
    RandomRotation,  # Apply random rotation to images
    RandomResizedCrop,  # Crop and resize images randomly
    RandomHorizontalFlip,  # Apply random horizontal flip
    RandomAdjustSharpness,  # Adjust sharpness randomly
    Resize,  # Resize images
    ToTensor  # Convert images to PyTorch tensors
)
import itertools  # Import 'itertools' for iterators and looping

model_checkpoint = "motheecreator/vit-Facial-Expression-Recognition" # pre-trained model from which to fine-tune

from datasets import load_metric

metric = load_metric("accuracy")

from datasets import load_dataset

af_dataset = load_dataset("imagefolder", data_dir="/kaggle/input/affectnet-training-data")

af_dataset

from datasets import DatasetDict, ClassLabel

# Assuming `dataset` is already defined
# Get the label names
label_names = af_dataset['train'].features['label'].names

# Get the index of the 'contempt' label
contempt_index = label_names.index('contempt')

# Filter out the rows with 'contempt' label
filtered_dataset = af_dataset['train'].filter(lambda example: example['label'] != contempt_index)

# Remove 'contempt' from the label names
new_label_names = [name for name in label_names if name != 'contempt']

# Create a new ClassLabel feature without 'contempt'
new_label_feature = ClassLabel(names=new_label_names)

# Function to remap labels to the new indices
def remap_label(label):
    return new_label_feature.str2int(label_names[label])

# Update the dataset's label feature
filtered_dataset = filtered_dataset.map(lambda example: {'label': remap_label(example['label'])})

# Update the dataset features
filtered_dataset = filtered_dataset.cast_column('label', new_label_feature)

# Update the DatasetDict
af_dataset = DatasetDict({'train': filtered_dataset})

# Verify the change
print(af_dataset)

from datasets import DatasetDict, ClassLabel

# Assuming `dataset` is already defined

# Get the label names
label_names = af_dataset['train'].features['label'].names

# Check if 'anger' exists in label_names before changing it
if 'anger' in label_names:
    # Change 'anger' to 'angry' in label names
    new_label_names = [name if name != 'anger' else 'angry' for name in label_names]

    # Update the label names in the dataset
    af_dataset['train'] = af_dataset['train'].rename_column('label', 'old_label')
    af_dataset['train'] = af_dataset['train'].rename_column('old_label', 'label')

    # Update the label 'anger' to 'angry' in the dataset
    af_dataset['train'] = af_dataset['train'].map(lambda example: {'label': 'angry' if example['label'] == 'anger' else example['label']})

    # Update the ClassLabel feature
    new_label_feature = ClassLabel(names=new_label_names)

    # Update the dataset's label feature
    af_dataset['train'] = af_dataset['train'].cast_column('label', new_label_feature)

# Verify the change
print(af_dataset)

fer_dataset = load_dataset("imagefolder", data_dir="/kaggle/input/fer2013")

fer_dataset

mmi_dataset = load_dataset("imagefolder", data_dir="/kaggle/input/mma-facial-expression")

combined_dataset = concatenate_datasets([af_dataset['train'],fer_dataset['train'],mmi_dataset['train']])

dataset = DatasetDict()

dataset['train'] = combined_dataset

dataset

dataset['train'][0]

dataset['train'].features

labels = dataset["train"].features["label"].names
label2id, id2label = dict(), dict()
for i, label in enumerate(labels):
    label2id[label] = i
    id2label[i] = label

label2id

image_processor  = AutoImageProcessor.from_pretrained(model_checkpoint)
image_processor

# Retrieve the image mean and standard deviation used for normalization
image_mean, image_std = image_processor.image_mean, image_processor.image_std

# Get the size (height) of the ViT model's input images
size = image_processor.size["height"]
print("Size: ", size)

# Define a normalization transformation for the input images
normalize = Normalize(mean=image_mean, std=image_std)

# Define a set of transformations for training data
train_tf = Compose(
    [
        Resize((size, size)),             # Resize images to the ViT model's input size
        RandomRotation(90),               # Apply random rotation
        RandomAdjustSharpness(2),         # Adjust sharpness randomly
        RandomHorizontalFlip(0.5),        # Random horizontal flip
        ToTensor(),                       # Convert images to tensors
        normalize                          # Normalize images using mean and std
    ]
)
# Define a set of transformations for validation data
val_tf = Compose(
    [
        Resize((size, size)),             # Resize images to the ViT model's input size
        ToTensor(),                       # Convert images to tensors
        normalize                         # Normalize images using mean and std
    ]
)

# Define a function to apply training transformations to a batch of examples
def train_transforms(examples):
    examples['pixel_values'] = [train_tf(image.convert("RGB")) for image in examples['image']]
    return examples

# Define a function to apply validation transformations to a batch of examples
def val_transforms(examples):
    examples['pixel_values'] = [val_tf(image.convert("RGB")) for image in examples['image']]
    return examples

# split up training into training + validation
splits = dataset["train"].train_test_split(test_size=0.2)
train_data = splits['train']
val_data = splits['test']

train_data

val_data

train_data.set_transform(train_transforms)
val_data.set_transform(val_transforms)

train_data[0]


val_data[0]

model = AutoModelForImageClassification.from_pretrained(
    model_checkpoint, 
    label2id=label2id,
    id2label=id2label,
    ignore_mismatched_sizes = True, # provide this in case you're planning to fine-tune an already fine-tuned checkpoint
)

notebook_login()


model_name = model_checkpoint.split("/")[-1]

args = TrainingArguments(
    f"{model_name}",
    remove_unused_columns=False,
    evaluation_strategy="steps",
    save_strategy="steps",  # Align with evaluation_strategy
    learning_rate=3e-5,
    lr_scheduler_type="cosine",
    auto_find_batch_size=True,
    per_device_train_batch_size=32,
    gradient_accumulation_steps=8,
    per_device_eval_batch_size=32,
    weight_decay=0.1,
    num_train_epochs=3,
    warmup_steps=1000,
    logging_steps=50,
    eval_steps=100,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    push_to_hub=True,
    report_to="none"
)

# the compute_metrics function takes a Named Tuple as input:
# predictions, which are the logits of the model as Numpy arrays,
# and label_ids, which are the ground-truth labels as Numpy arrays.
def compute_metrics(eval_pred):
    """Computes accuracy on a batch of predictions"""
    predictions = np.argmax(eval_pred.predictions, axis=1)
    return metric.compute(predictions=predictions, references=eval_pred.label_ids)

def collate_fn(examples):
    pixel_values = torch.stack([example["pixel_values"] for example in examples])
    labels = torch.tensor([example["label"] for example in examples])
    return {"pixel_values": pixel_values, "labels": labels}


trainer = Trainer(
    model,
    args,
    train_dataset=train_data,
    eval_dataset=val_data,
    tokenizer=image_processor,
    compute_metrics=compute_metrics,
    data_collator=collate_fn,
)

train_results = trainer.train()

metrics = trainer.evaluate()
# some nice to haves:
trainer.log_metrics("eval", metrics)
trainer.save_metrics("eval", metrics)


trainer.push_to_hub()

# Use the trained 'trainer' to make predictions on the 'test_data'.
outputs = trainer.predict(val_data)

# Print the metrics obtained from the prediction outputs.
print(outputs.metrics)

pipe=pipeline(model = 'motheecreator/vit-Facial-Expression-Recognition')


import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Load the image file
image_path = '/kaggle/input/testing-fer/testing_FER/happy2.jpg'  # Replace with the actual path to your image file
img = mpimg.imread(image_path)

# Display the image
plt.imshow(img)
plt.axis('off')  # Turn off axis labels
plt.show()

pipe("/kaggle/input/testing-fer/testing_FER/happy2.jpg")

labels_list = ['sad', 'disgust', 'angry', 'neutral', 'fear', 'surprise', 'happy'] # list(set(labels))
# Extract the true labels from the model outputs
y_true = outputs.label_ids

# Predict the labels by selecting the class with the highest probability
y_pred = outputs.predictions.argmax(1)

# Define a function to plot a confusion matrix
def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):
    """
    This function plots a confusion matrix.

    Parameters:
        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.
        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].
        title (str): Title for the plot.
        cmap (matplotlib colormap): Colormap for the plot.
    """
    # Create a figure with a specified size
    plt.figure(figsize=figsize)
    
    # Display the confusion matrix as an image with a colormap
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    # Define tick marks and labels for the classes on the axes
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)

    fmt = '.0f'
    # Add text annotations to the plot indicating the values in the cells
    thresh = cm.max() / 2.0
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    # Label the axes
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

    # Ensure the plot layout is tight
    plt.tight_layout()
    # Display the plot
    plt.show()

# Calculate accuracy and F1 score
accuracy = accuracy_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred, average='macro')

# Display accuracy and F1 score
print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")

# Get the confusion matrix if there are a small number of labels
if len(labels_list) <= 150:
    # Compute the confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Plot the confusion matrix using the defined function
    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))
    
# Finally, display classification report
print()
print("Classification report:")
print()
print(classification_report(y_true, y_pred, target_names=labels_list, digits=4))
06/04/25, 19:12 - Nishita ğŸª°: pip install opencv-python

import numpy as np 
import pandas as pd 
import os

import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import keras
from keras.preprocessing import image
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import cv2
from tensorflow.keras.applications import VGG16, InceptionResNetV2
from keras import regularizers
from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax

train_dir = r"E:\EX2\emotion\archive (2)" #passing the path with training images

img_size = 96 #original size of the image
epochs = 150
batch_size = 96
lr=0.001
seed=32
print(seed)


train_datagen = ImageDataGenerator(#rotation_range = 180,
                                         width_shift_range = 0.1,
                                         height_shift_range = 0.1,
                                         horizontal_flip = True,
                                         rescale = 1./255,
                                         #zoom_range = 0.2,
                                         validation_split = 0.2
                                        )
validation_datagen = ImageDataGenerator(rescale = 1./255,
                                         validation_split = 0.2)


train_generator = train_datagen.flow_from_directory(directory = train_dir,
                                                    target_size = (img_size,img_size),
                                                    batch_size = 64,
                                                    color_mode = "grayscale",
                                                    class_mode = "categorical",
                                                    subset = "training"
                                                   )
validation_generator = validation_datagen.flow_from_directory( directory = train_dir,
                                                              target_size = (img_size,img_size),
                                                              batch_size = 64,
                                                              color_mode = "grayscale",
                                                              class_mode = "categorical",
                                                              subset = "validation"
                                                             )

model= tf.keras.models.Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(img_size, img_size,1)))
model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128,(5,5), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
    
model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten()) 
model.add(Dense(256,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))
    
model.add(Dense(512,activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.25))

model.add(Dense(7, activation='softmax'))

model.compile(
    optimizer = Adam(0.001), 
    loss='categorical_crossentropy', 
    metrics=['accuracy']
  )
model.summary()

def compute_flops(model):
    tot_flops = 0

    for layer in model.layers:
        layertype = layer.__class__.__name__

        if layertype == "Dense":
            input_units = layer.input.shape[-1]
            output_units = layer.output.shape[-1]
            flops = 2 * input_units * output_units  # Multiplication & Addition FLOPs

        elif layertype == "Conv2D":
            _, h, w, in_channels = layer.input.shape
            kernel_h, kernel_w, _, out_channels = layer.kernel.shape
            flops = 2 * h * w * kernel_h * kernel_w * in_channels * out_channels  # Conv FLOPs

        else:
            flops = 0

        tot_flops += flops

    return tot_flops

# Compute and print FLOPs
total_flops = compute_flops(model)
print(f"Total FLOPs: {total_flops:,}")

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

checkpoint = ModelCheckpoint(
    'model_optimal.keras',  # Use .keras extension here
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1,
    mode='auto',
    save_weights_only=False
)

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    restore_best_weights=True
)

history = model.fit(x = train_generator,epochs = epochs,
                    validation_data = validation_generator,
                   callbacks=checkpoint)

fig , ax = plt.subplots(1,2)
train_acc = history.history['accuracy']
train_loss = history.history['loss']
fig.set_size_inches(12,4)

ax[0].plot(history.history['accuracy'])
ax[0].plot(history.history['val_accuracy'])
ax[0].set_title('Training Accuracy vs Validation Accuracy')
ax[0].set_ylabel('Accuracy')
ax[0].set_xlabel('Epoch')
ax[0].legend(['Train', 'Validation'], loc='upper left')

ax[1].plot(history.history['loss'])
ax[1].plot(history.history['val_loss'])
ax[1].set_title('Training Loss vs Validation Loss')
ax[1].set_ylabel('Loss')
ax[1].set_xlabel('Epoch')
ax[1].legend(['Train', 'Validation'], loc='upper left')

plt.show()

from keras.models import load_model

model = load_model(r"E:\EX2\emotion\model_optimal.keras")

train_loss, train_acc = model.evaluate(train_generator)
test_loss, test_acc   = model.evaluate(validation_generator)
print("final train accuracy = {:.2f} , validation accuracy = {:.2f}".format(train_acc*100, test_acc*100))

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Path to your image
img_path = r'E:\EX2\emotion\archive (2)\disgust\S005_001_00000009.png'  # Replace with the path to the image you want to predict

# Load and preprocess the image
img = image.load_img(img_path, target_size=(img_size, img_size), color_mode="grayscale")
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Normalize the image, as done during training

# Make a prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions, axis=1)[0]

# Print the output
print("Predicted class:", predicted_class)
print("Confidence scores:", predictions[0])  # Shows the confidence score for each class

# If you have class names, you can display the class name instead of the class index
class_names = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']  # Replace with actual class names
predicted_class_name = class_names[predicted_class]
print("Predicted class name:", predicted_class_name)

# Display the image with the predicted class name
plt.imshow(img, cmap='gray')
plt.title(f"Predicted: {predicted_class_name}")
plt.axis('off')  # Turn off axis
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Path to your image
img_path = r'E:\EX2\emotion\archive (2)\happy\S034_005_00000008.png'  # Replace with the path to the image you want to predict

# Load and preprocess the image
img = image.load_img(img_path, target_size=(img_size, img_size), color_mode="grayscale")
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Normalize the image, as done during training

# Make a prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions, axis=1)[0]

# Print the output
print("Predicted class:", predicted_class)
print("Confidence scores:", predictions[0])  # Shows the confidence score for each class

# If you have class names, you can display the class name instead of the class index
class_names = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']  # Replace with actual class names
predicted_class_name = class_names[predicted_class]
print("Predicted class name:", predicted_class_name)

# Display the image with the predicted class name
plt.imshow(img, cmap='gray')
plt.title(f"Predicted: {predicted_class_name}")
plt.axis('off')  # Turn off axis
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

# Path to your image
img_path = r'E:\EX2\emotion\archive (2)\surprise\S035_001_00000014.png'  # Replace with the path to the image you want to predict

# Load and preprocess the image
img = image.load_img(img_path, target_size=(img_size, img_size), color_mode="grayscale")
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
img_array /= 255.0  # Normalize the image, as done during training

# Make a prediction
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions, axis=1)[0]

# Print the output
print("Predicted class:", predicted_class)
print("Confidence scores:", predictions[0])  # Shows the confidence score for each class

# If you have class names, you can display the class name instead of the class index
class_names = ['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']  # Replace with actual class names
predicted_class_name = class_names[predicted_class]
print("Predicted class name:", predicted_class_name)

# Display the image with the predicted class name
plt.imshow(img, cmap='gray')
plt.title(f"Predicted: {predicted_class_name}")
plt.axis('off')  # Turn off axis
plt.show()
07/04/25, 17:56 - Nishita ğŸª°: <Media omitted>
07/04/25, 17:56 - Nishita ğŸª°: ğŸ‘†Imp for MLA cie 3 evaluation
07/04/25, 22:06 - rohxn 03: In a meeting nishita 
Ill be back
07/04/25, 22:07 - Gass: Dai
07/04/25, 22:07 - Gass: Call me back when you finish your meeting
07/04/25, 22:11 - Nishita ğŸª°: Ok
07/04/25, 22:11 - Nishita ğŸª°: Begaa call maduu
07/04/25, 22:13 - rohxn 03: <Media omitted>
07/04/25, 22:13 - rohxn 03: Haa finished
07/04/25, 22:13 - rohxn 03: Call
07/04/25, 22:14 - Gass: Ok but please check asap avnu submit madu andha
07/04/25, 22:18 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:18 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:18 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:18 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:19 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:19 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:19 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:19 - Gass: Raw? <This message was edited>
07/04/25, 22:19 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:20 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:20 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:20 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:21 - Gass: Ok thank you
07/04/25, 22:22 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:22 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:22 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:23 - Wifeyâ¤ï¸: <Media omitted>
07/04/25, 22:23 - Wifeyâ¤ï¸: <Media omitted>
08/04/25, 13:05 - Wifeyâ¤ï¸: Nishita upload this file in colab and create a new cell for confusion matrix, I need that graph so
08/04/25, 13:05 - Wifeyâ¤ï¸: <Media omitted>
08/04/25, 13:06 - Wifeyâ¤ï¸: like this for cnn we should need
08/04/25, 17:17 - Nishita ğŸª°: TOC exam is on 15th Tuesday
08/04/25, 17:17 - Nishita ğŸª°: 11:10 to 1:00
08/04/25, 17:17 - Nishita ğŸª°: Check timetable
08/04/25, 19:20 - Wifeyâ¤ï¸: Shistry Ma'am is on leave soo u ppl just call and ask her about your marks
08/04/25, 19:26 - Nishita ğŸª°: Guna should we msg her better
08/04/25, 19:27 - Nishita ğŸª°: ??
08/04/25, 19:27 - Wifeyâ¤ï¸: Haa maduu pa
08/04/25, 19:29 - Wifeyâ¤ï¸: ğŸ™„
08/04/25, 19:31 - Nishita ğŸª°: Number kalsu
08/04/25, 19:31 - Wifeyâ¤ï¸: ahh
08/04/25, 19:31 - Wifeyâ¤ï¸: +91 96930 36030
08/04/25, 20:15 - rohxn 03: Whats this??
08/04/25, 20:15 - Wifeyâ¤ï¸: maam's no
08/04/25, 20:15 - Wifeyâ¤ï¸: shistry kumari
08/04/25, 20:18 - rohxn 03: Okkk
08/04/25, 20:19 - rohxn 03: Hey @918799146002 How many references should we add on report
He didnt mentioned
08/04/25, 20:20 - rohxn 03: @919663957450 Collect referemces from google scholars
Type 
1. FER using cnn
2. FER using ViT
Collect 5 links each begaaa
08/04/25, 20:28 - Wifeyâ¤ï¸: ok
08/04/25, 20:30 - Wifeyâ¤ï¸: https://www.mdpi.com/1088298
08/04/25, 20:31 - Wifeyâ¤ï¸: like this??
08/04/25, 20:33 - Wifeyâ¤ï¸: chuu
08/04/25, 20:35 - Wifeyâ¤ï¸: S. B. Musa and H. Tjandrasa, "Analisis fitur sinyal emosi eeg berdasarkan hybrid decompotion", ENERGY, vol. 7, no. 1, pp. 7-12, 2017.
Google Scholar
08/04/25, 20:35 - Wifeyâ¤ï¸: or like this
08/04/25, 20:36 - Wifeyâ¤ï¸: @916238330557 is this how I supposed to do ?
08/04/25, 20:56 - Wifeyâ¤ï¸: FER REFERENCE

1) DOI: 10.1109/ICECCME55909.2022.9988371
2) DOI: 10.1109/ICSGRC62081.2024.10691228
3) DOI: 10.1109/ACCESS.2024.3380847
4) DOI: 10.1109/ICEARS53579.2022.9751735
5) DOI: 10.1109/ACCESS.2019.2949741
08/04/25, 20:56 - Wifeyâ¤ï¸: FER using ViT

1) DOI: 10.1109/CommNet56067.2022.9993933
2) https://doi.org/10.3390/s22103729
3) https://doi.org/10.1016/j.ins.2021.08.043
4) DOI: 10.1109/SMC53992.2023.10394018
5) DOI: 10.1109/3ict64318.2024.10824313
08/04/25, 20:56 - Wifeyâ¤ï¸: like this Ive done .....
08/04/25, 20:57 - rohxn 03: Https should be there
08/04/25, 20:57 - rohxn 03: Like 2 and 3
08/04/25, 20:57 - Wifeyâ¤ï¸: Doi alla?
08/04/25, 20:57 - rohxn 03: When we click it should directly go to the webpage
08/04/25, 20:57 - Wifeyâ¤ï¸: In ppt we can make it as link <This message was edited>
08/04/25, 20:58 - rohxn 03: If we copy the line and paste will it redirect to the corresponding research paper??
08/04/25, 20:58 - rohxn 03: Then ok
08/04/25, 20:58 - Nishita ğŸª°: No he didn't 
I think 5 is ok
08/04/25, 20:59 - rohxn 03: Fine we'll give 5 each
08/04/25, 20:59 - Wifeyâ¤ï¸: yes
08/04/25, 20:59 - rohxn 03: Fine
08/04/25, 21:00 - Wifeyâ¤ï¸: should i search
08/04/25, 21:00 - Wifeyâ¤ï¸: other
08/04/25, 21:00 - rohxn 03: No need this is fyn
08/04/25, 21:00 - Wifeyâ¤ï¸: can u just check
08/04/25, 21:01 - Wifeyâ¤ï¸: whether it is directly going ot that page
08/04/25, 21:01 - rohxn 03: <Media omitted>
08/04/25, 21:03 - Wifeyâ¤ï¸: <Media omitted>
08/04/25, 21:03 - Wifeyâ¤ï¸: if i copy paste that DOI link it is howing like this
08/04/25, 21:04 - rohxn 03: <Media omitted>
08/04/25, 21:08 - Wifeyâ¤ï¸: FER REFERENCES 

1.  https://www.researchgate.net/publication/376223715_Facial_Emotion_Recognition_usign_CNN?utm_source=chatgpt.com

2.  https://www.researchgate.net/publication/381479599_Facial_Emotion_Recognition_And_Detection_Using_Convolutional_Neural_Network?utm_source=chatgpt.com

3.  https://www.researchgate.net/publication/380241292_Facial_Expression_Recognition_Using_Convolutional_Neural_Network

4.  https://www.researchgate.net/publication/379188944_Facial_Emotion_Recognition_and_Synthesis_with_Convolutional_Neural_Networks

5.  https://www.researchgate.net/publication/384358835_From_Image_to_Emotion_Exploring_CNN_Architectures_for_Facial_Emotion_Recognition
08/04/25, 21:09 - Wifeyâ¤ï¸: LIKE THIS RYT??
08/04/25, 21:16 - Wifeyâ¤ï¸: FER using ViT REFERENCES


1.  https://www.researchgate.net/publication/376854046_Recognition_of_Facial_Expressions_Using_Vision_Transformer_Reconocimiento_de_expresiones_faciales_con_vision_transformer

2.  https://www.researchgate.net/publication/373526808_Fine_Tuning_Vision_Transformer_Model_for_Facial_Emotion_Recognition_Performance_Analysis_for_Human-Machine_Teaming?utm_source=chatgpt.com

3.  https://www.researchgate.net/publication/362714323_ViTFER_Facial_Emotion_Recognition_with_Vision_Transformers?utm_source=chatgpt.com

4.  https://www.researchgate.net/publication/388513380_Enhanced_Facial_Emotion_Recognition_Using_Vision_Transformer_Models

5.  https://www.researchgate.net/publication/362714323_ViTFER_Facial_Emotion_Recognition_with_Vision_Transformers
08/04/25, 21:17 - Wifeyâ¤ï¸: everything is directly going to that page
08/04/25, 21:25 - rohxn 03: Fine
08/04/25, 21:44 - Wifeyâ¤ï¸: Ok
08/04/25, 22:33 - Nishita ğŸª°: @916238330557 come tmr at 10:30 to Soef block ground floor
08/04/25, 22:37 - rohxn 03: Reason?
08/04/25, 22:37 - Nishita ğŸª°: NOC
08/04/25, 22:37 - rohxn 03: She told??
08/04/25, 22:37 - Nishita ğŸª°: I called you for something else
08/04/25, 22:37 - Nishita ğŸª°: Guna told
08/04/25, 22:37 - rohxn 03: Call call
09/04/25, 07:31 - rohxn 03: @918799146002 today when ull be free after class hours?
09/04/25, 10:16 - Nishita ğŸª°: U know after lunch 
Today there are no minors work
09/04/25, 10:16 - Nishita ğŸª°: Where are you ??
09/04/25, 10:17 - Wifeyâ¤ï¸: <Media omitted>
09/04/25, 10:24 - Nishita ğŸª°: Don't send voice message 
Tell in words
09/04/25, 10:24 - Wifeyâ¤ï¸: It's okay after your class listem
09/04/25, 10:24 - Wifeyâ¤ï¸: urgent illaaa
09/04/25, 10:24 - Nishita ğŸª°: Where are you now ??
09/04/25, 10:25 - Wifeyâ¤ï¸: Classroom
09/04/25, 10:25 - Nishita ğŸª°: Should we go to Shruti now ??
09/04/25, 10:26 - Wifeyâ¤ï¸: No
09/04/25, 10:26 - Nishita ğŸª°: Ok
09/04/25, 10:59 - Wifeyâ¤ï¸: Where r u both
09/04/25, 10:59 - Wifeyâ¤ï¸: Bannii ivagaaa
09/04/25, 11:21 - Nishita ğŸª°: This message was deleted
09/04/25, 11:22 - Nishita ğŸª°: This message was deleted
09/04/25, 11:42 - Nishita ğŸª°: <Media omitted>
09/04/25, 13:54 - rohxn 03: @918799146002 When ull come
09/04/25, 13:54 - rohxn 03: Mention the time
09/04/25, 13:55 - rohxn 03: Then we can go to eat
09/04/25, 13:55 - rohxn 03: We have to gaurd the epochs rytğŸ˜­
09/04/25, 14:09 - Nishita ğŸª°: 2:15 I leave
09/04/25, 14:09 - Nishita ğŸª°: In 5 mins I will come okk
09/04/25, 15:42 - Nishita ğŸª°: Where are you both ??
09/04/25, 15:42 - Nishita ğŸª°: Come fast
09/04/25, 20:00 - Nishita ğŸª°: Hey @919663957450 we have a lot of work to do but as we lost a lot of time we couldn't complete it.
So can we meet tomorrow somewhere outside??
09/04/25, 20:01 - Wifeyâ¤ï¸: outside ahh
09/04/25, 20:01 - Wifeyâ¤ï¸: nale holidayyyyyyy
09/04/25, 20:01 - Nishita ğŸª°: Yess
09/04/25, 20:02 - rohxn 03: Oooooo yas yas
09/04/25, 20:02 - Wifeyâ¤ï¸: yen work ide
09/04/25, 20:02 - Wifeyâ¤ï¸: nanu maneli modoke agalvaa??
09/04/25, 20:02 - rohxn 03: Agallaaa
09/04/25, 20:02 - Nishita ğŸª°: Check what I sent to you first then do yessssss
09/04/25, 20:02 - rohxn 03: We need 2 laps
09/04/25, 20:02 - rohxn 03: That to charging pointu irbekku alvaa
09/04/25, 20:03 - Wifeyâ¤ï¸: ayyoo yen madly nanu then
09/04/25, 20:03 - rohxn 03: Haaa okğŸ˜’
09/04/25, 20:03 - rohxn 03: Run around ur home 3 times
09/04/25, 20:03 - Wifeyâ¤ï¸: allaa maneli I cant do ahh
09/04/25, 20:03 - rohxn 03: ğŸ˜’
09/04/25, 20:03 - rohxn 03: U can
09/04/25, 20:03 - rohxn 03: This one
09/04/25, 20:03 - rohxn 03: Baai ilvaa ath muchkondu baaa
Jyaasthi work ide
09/04/25, 20:04 - Wifeyâ¤ï¸: Ayyo howdaa
09/04/25, 20:04 - rohxn 03: Ayyuu howduuuğŸ˜
09/04/25, 20:04 - Nishita ğŸª°: Only work nothing else otherwise you both only go
09/04/25, 20:04 - Wifeyâ¤ï¸: Where to
09/04/25, 20:04 - rohxn 03: <Media omitted>
09/04/25, 20:04 - Nishita ğŸª°: That we will decide
09/04/25, 20:04 - rohxn 03: Rr mall??
09/04/25, 20:05 - Wifeyâ¤ï¸: Ooo
09/04/25, 20:05 - rohxn 03: ooO
09/04/25, 20:05 - Wifeyâ¤ï¸: ğŸ™„
09/04/25, 20:06 - Nishita ğŸª°: I will literally slap you ğŸ˜¤
09/04/25, 20:06 - Wifeyâ¤ï¸: Time???
09/04/25, 20:06 - Nishita ğŸª°: Sir will only tell ??
09/04/25, 20:07 - rohxn 03: Belegeee 10 30 then only these shops will open ryt
09/04/25, 20:07 - rohxn 03: But even if we go to mall charging points irbekku alvaa
09/04/25, 20:07 - rohxn 03: Especially nishitas lap
09/04/25, 20:07 - Wifeyâ¤ï¸: California burrito alli ide
09/04/25, 20:07 - Wifeyâ¤ï¸: Charging point
09/04/25, 20:07 - rohxn 03: But we cant spent a whole day in there
09/04/25, 20:07 - Wifeyâ¤ï¸: Under table only it is there
09/04/25, 20:08 - Wifeyâ¤ï¸: Adee.... Soo wt todo
09/04/25, 20:08 - rohxn 03: Noon alli we ll go to eat ryt
09/04/25, 20:08 - rohxn 03: Before that nishitaaaa.....
09/04/25, 20:08 - Nishita ğŸª°: Then what you will go for shopping or what ??
09/04/25, 20:08 - rohxn 03: If ur lap is full charge how many hours we get
09/04/25, 20:08 - rohxn 03: Ayyoooo bvc r u planning to sit in CB for entire day
09/04/25, 20:08 - Nishita ğŸª°: Max to max 3 hrs
09/04/25, 20:09 - rohxn 03: U be a worker nishita
09/04/25, 20:09 - rohxn 03: Clean all the tavles while we chargeğŸ¤¨
09/04/25, 20:09 - rohxn 03: Shit!!
09/04/25, 20:09 - rohxn 03: Lulu???
09/04/25, 20:09 - rohxn 03: Charging ports idyaaa
09/04/25, 20:09 - Nishita ğŸª°: It will be very far da ??
09/04/25, 20:10 - Nishita ğŸª°: Should we search for some cyber cafe ??
09/04/25, 20:10 - rohxn 03: Should i bring my extention board
09/04/25, 20:10 - rohxn 03: I have one
09/04/25, 20:10 - rohxn 03: Cyberaaaa
09/04/25, 20:10 - rohxn 03: Why
09/04/25, 20:11 - Nishita ğŸª°: There we can sit for the whole day ??
09/04/25, 20:11 - rohxn 03: Really?
09/04/25, 20:11 - Nishita ğŸª°: I think so
09/04/25, 20:11 - rohxn 03: Where are they situated
09/04/25, 20:11 - Nishita ğŸª°: Idk we need to search
09/04/25, 20:11 - rohxn 03: Allaaa here library open aagalvaa??
09/04/25, 20:12 - Nishita ğŸª°: Maybe it will be but you can only go I think so
09/04/25, 20:12 - Wifeyâ¤ï¸: nale if I come they will not allow me in
09/04/25, 20:13 - rohxn 03: Who will not allow u whereğŸ¤¨
09/04/25, 20:13 - Wifeyâ¤ï¸: college
09/04/25, 20:13 - Nishita ğŸª°: Security idoits
09/04/25, 20:13 - rohxn 03: College Bedaa then
09/04/25, 20:13 - Wifeyâ¤ï¸: ahhh
09/04/25, 20:13 - rohxn 03: But where can we sit and work
09/04/25, 20:13 - Wifeyâ¤ï¸: i really donno eeeeeeeee
09/04/25, 20:14 - Nishita ğŸª°: Rohan u went to cb right ?? What time ??
09/04/25, 20:14 - rohxn 03: This time only
09/04/25, 20:14 - rohxn 03: We can go there
09/04/25, 20:14 - rohxn 03: But how can we sit there for hours without ordering anything
09/04/25, 20:15 - rohxn 03: @919663957450 Telk ur amma or appa naale some registration ide so u need 300
09/04/25, 20:15 - Wifeyâ¤ï¸: adhu nija
09/04/25, 20:15 - rohxn 03: We need to eat
09/04/25, 20:15 - Wifeyâ¤ï¸: ahh
09/04/25, 20:15 - Nishita ğŸª°: Ya that is for sure we need to
09/04/25, 20:16 - rohxn 03: <Media omitted>
09/04/25, 20:16 - Wifeyâ¤ï¸: ahh i will ask
09/04/25, 20:16 - Wifeyâ¤ï¸: let me see
09/04/25, 20:17 - Nishita ğŸª°: Okk
09/04/25, 20:17 - rohxn 03: See allaa do
Illaa andre i cant buy u, other than tissue paper
09/04/25, 20:17 - Nishita ğŸª°: ğŸ¤£ğŸ¤£
09/04/25, 20:17 - Wifeyâ¤ï¸: ğŸ™„ğŸ™„
09/04/25, 20:22 - rohxn 03: ğŸ˜
09/04/25, 20:23 - Wifeyâ¤ï¸: ookok
09/04/25, 20:39 - Nishita ğŸª°: @916238330557 is this correct ??
09/04/25, 20:39 - Nishita ğŸª°: <Media omitted>
09/04/25, 21:26 - rohxn 03: <Media omitted>
09/04/25, 21:33 - rohxn 03: @918799146002 create a gmeet for 10 30 if u both are free ok
09/04/25, 21:33 - rohxn 03: And @919663957450 U
09/04/25, 21:36 - Wifeyâ¤ï¸: 10.30
09/04/25, 21:36 - Wifeyâ¤ï¸: Ah
09/04/25, 21:36 - Wifeyâ¤ï¸: This message was deleted
09/04/25, 21:47 - Wifeyâ¤ï¸: Send the ipynb file if u done !
09/04/25, 22:08 - rohxn 03: Maribeda ok
09/04/25, 22:09 - rohxn 03: Take ur time and do
09/04/25, 22:13 - Nishita ğŸª°: Hmm
09/04/25, 22:13 - Nishita ğŸª°: Now I am eating
09/04/25, 22:14 - Nishita ğŸª°: Can we do gmeet at 10:45 or people start at 10:30 I will join later ??
09/04/25, 22:14 - Nishita ğŸª°: https://meet.google.com/mod-wvym-hvg
09/04/25, 22:14 - rohxn 03: No u come when u done
09/04/25, 22:14 - rohxn 03: And u too @919663957450
09/04/25, 22:15 - Nishita ğŸª°: Okk
09/04/25, 22:15 - rohxn 03: But don't be too late
09/04/25, 22:15 - rohxn 03: Thats it
09/04/25, 22:15 - Wifeyâ¤ï¸: U ppl joined
09/04/25, 22:46 - Wifeyâ¤ï¸: @918799146002  aythaa??? <This message was edited>
09/04/25, 22:46 - Wifeyâ¤ï¸: swalpa bega baa
09/04/25, 22:46 - Wifeyâ¤ï¸: if everyone sleep I cant talk
09/04/25, 22:49 - rohxn 03: When will everyone sleeps??
09/04/25, 22:49 - Wifeyâ¤ï¸: they will sleep now
09/04/25, 22:49 - Wifeyâ¤ï¸: 11 aythu alvaa
09/04/25, 22:49 - Wifeyâ¤ï¸: i mean almost
09/04/25, 22:55 - rohxn 03: @918799146002
09/04/25, 22:55 - rohxn 03: Naale morning meeting is there ok
09/04/25, 22:55 - rohxn 03: Pls dont miss
09/04/25, 22:55 - rohxn 03: Its really urgent
09/04/25, 22:55 - rohxn 03: By 7 yellaru join aagbekku
09/04/25, 22:55 - rohxn 03: Its really important
09/04/25, 22:56 - rohxn 03: @918799146002  and @919663957450  u ppl have join without fail
09/04/25, 22:56 - Wifeyâ¤ï¸: ok
09/04/25, 22:56 - Nishita ğŸª°: I came is it possible now
09/04/25, 22:56 - rohxn 03: Ammuu??
09/04/25, 22:56 - rohxn 03: Is it
09/04/25, 22:56 - Wifeyâ¤ï¸: hmmok
09/04/25, 22:57 - rohxn 03: I came
09/04/25, 22:58 - rohxn 03: We cant hear
09/04/25, 22:58 - rohxn 03: A single thing ammu
09/04/25, 23:21 - Wifeyâ¤ï¸: Haa
09/04/25, 23:21 - Wifeyâ¤ï¸: Assign madi task
09/04/25, 23:21 - rohxn 03: Wait
09/04/25, 23:21 - Wifeyâ¤ï¸: Let me go sleepğŸ˜
09/04/25, 23:26 - Nishita ğŸª°: <Media omitted>
09/04/25, 23:29 - rohxn 03: @919663957450 Tasks
1. Get reference for FER using both CNN and ViT model(in this ppt we r comparing these 2 model which is better), so u need to find ppts based on that 

2. Ppt design part is completely ur responsibility, so search in google, canva, presentation.ai, like these websites and try to build a good looking ppt


3. Ill send our research paper or report, make it plagiarism free


4. Search in youtube for a good 3d game using unity see the first part and last part so u have an idea how the game looks like when playing, if u find it well sent the youtube link in group
09/04/25, 23:32 - Wifeyâ¤ï¸: Okayy
09/04/25, 23:33 - rohxn 03: @918799146002 Tasks

1. Help @919663957450 To make a ppt without tech error and content error, get more clarity on our problem statement(u can refer the research paper if u want) so u can help her create one

2. Try modifying the confusion matrix for better result (u can take ur time as its not a must now)

3. Search in youtube for a good 3d game using unity see the first part and last part so u have an idea how the game looks like when playing, if u find it well sent the youtube link in group
09/04/25, 23:35 - rohxn 03: @919663957450 Task 4 and @918799146002 Task 3 
Do this before we meet tomorrow, that helps to complete fast
10/04/25, 09:44 - rohxn 03: <Media omitted>
10/04/25, 09:44 - rohxn 03: Sunil sir
10/04/25, 10:02 - Wifeyâ¤ï¸: @918799146002 When ur planning to leave
10/04/25, 10:29 - Nishita ğŸª°: I will leave pg by 10:45
10/04/25, 10:30 - Nishita ğŸª°: @916238330557 bring my parcel with you don't forget
10/04/25, 10:35 - rohxn 03: No i wont
10/04/25, 10:35 - rohxn 03: Leave at 11
10/04/25, 10:35 - rohxn 03: I want to bath
10/04/25, 10:36 - Nishita ğŸª°: Y ğŸ˜¡
10/04/25, 10:36 - Nishita ğŸª°: Ok but it will take me time to reach the metro station ok
10/04/25, 10:49 - rohxn 03: Leave leave leave
10/04/25, 10:49 - rohxn 03: Im all ready
10/04/25, 10:49 - Wifeyâ¤ï¸: Im leaving noe
10/04/25, 10:49 - Wifeyâ¤ï¸: Now
10/04/25, 10:49 - Wifeyâ¤ï¸: Appa will drop me till college
10/04/25, 10:50 - Wifeyâ¤ï¸: @918799146002  be in front of college okay appa will be there he have to believe college is there antha sooo
10/04/25, 10:50 - rohxn 03: Then leave after 10 min ammu
10/04/25, 10:50 - rohxn 03: She have to be in main gate
10/04/25, 10:51 - rohxn 03: Appa make make u reacg within few minutes
10/04/25, 10:51 - Wifeyâ¤ï¸: It's okay by the time I reach she will be there
10/04/25, 10:53 - Nishita ğŸª°: I am leaving
10/04/25, 10:59 - Nishita ğŸª°: This message was deleted
10/04/25, 11:02 - Nishita ğŸª°: I reached where are you both ??
10/04/25, 11:07 - rohxn 03: Main gate
10/04/25, 11:42 - Wifeyâ¤ï¸: https://www.youtube.com/watch?v=rJqP5EesxLk&list=PLGUw8UNswJEOv8c5ZcoHarbON6mIEUFBC

see the first 30 sec and see u liked or not
10/04/25, 12:13 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 13:13 - Nishita ğŸª°: This message was deleted
10/04/25, 13:24 - Nishita ğŸª°: # Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.

import pandas as pd

import numpy as np

from matplotlib import pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import load_model

((X_train, Y_train), (X_test, Y_test)) = fashion_mnist.load_data()

class_labels = pd.Series(['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Code', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'])
labels_dict = class_labels.to_dict()
labels_dict()

np.random.seed(40)
for rand_num in np.random.randint(0, len(X_train), 5):
    plt.figure()
    plt.imshow(X_train[rand_num]), plt.axis('off')
    plt.title(labels_dict[Y_train[rand_num]])

X_train_reshaped = X_train.reshape(len(X_train), -1)
X_test_reshaped = X_test.reshape(len(X_test), -1)

X_train_norm = X_train_reshaped/255
X_test_norm = X_test_reshaped/255

n_features = X_train_norm.shape[1]
n_classes =  len(class_labels)

print('Number of input features (image pixels) : ', n_features)
print('Number of target classes (fashion categories) : ', n_classes)

Y_train_onehot = to_categorical(Y_train, num_classes = n_classes)
Y_test_onehot = to_categorical(Y_test, num_classes = n_classes)

X_train_final, X_valid, Y_train_final, Y_valid = train_test_split(X_train_norm, Y_train_onehot,
                                                                  test_size=0.16666)

print('Shape of data used for training, and shape of training targets : \n ', X_train.shape, ',', Y_train.shape)
print('Shape of data used for validation, and shape of validation targets: \n ', X_valid.shape, ',', Y_valid.shape)

model = Sequential()
model.add(Dense(1000, input_dim = n_features, activation='relu', use_bias=False))
model.add(Dense(1000, activation='relu', use_bias=False))
model.add(Dense(500, activation='relu', use_bias=False))
model.add(Dense(200, activation='relu', use_bias=False))
model.add(Dense(n_classes, activation='softmax', use_bias=False))
model.compile(loss='categorical_crossentropy', optimizer=Adam(0.0001), metrics=['accuracy'])

model.summary()

save_at = "model.keras"
save_best = ModelCheckpoint (save_at, monitor='val_accuracy', verbose=0,
                             save_best_only=True, save_weights_only=False, mode='max')

history = model.fit( X_train_final, Y_train_final,
                    epochs = 5, batch_size = 20,
                    callbacks=[save_best], verbose=1,
                    validation_data = (X_valid, Y_valid) )

plt.figure(figsize=(6, 5))
plt.plot(history.history['accuracy'], color='r')
plt.plot(history.history['val_accuracy'], color='b')
plt.title('Model Accuracy', weight='bold', fontsize=16)
plt.ylabel('accuracy', weight='bold', fontsize=14)
plt.xlabel('epoch', weight='bold', fontsize=14)
plt.ylim(0.5, 1)
plt.xticks(weight='bold', fontsize=12)
plt.yticks(weight='bold', fontsize=12)
plt.legend(['train', 'val'], loc='upper left', prop={'size': 14})
plt.grid(color = 'y', linewidth='0.5')
plt.show()

score = model.evaluate(X_test_norm, Y_test_onehot, verbose=0)
print('Accuracy over the test set: \n ', round((score[1]*100), 2), '%')

trained_model = load_model("model.keras")

trained_model.layers

total_no_layers = len(trained_model.layers)
print(total_no_layers)

#Pruning percentages

K = [0, 25, 50, 60, 70, 80, 90, 95, 97, 99]

all_weights = {}

for layer_no in range(total_no_layers - 1):         #All except the final layer                                                                          #only the first four dense layers are to be pruned
    layer_weights = (pd.DataFrame(trained_model.layers[layer_no].get_weights()[0]).stack()).to_dict()
    layer_weights = { (layer_no, k[0], k[1]): v for k, v in layer_weights.items() }
    all_weights.update(layer_weights)
all_weights_sorted = {k: v for k, v in sorted(all_weights.items(), key=lambda item: abs(item[1]))}

total_no_weights = len(all_weights_sorted)
total_no_weights

weight_pruning_scores = []

for pruning_percent in K:

    new_model = load_model("model.keras")
    new_weights = trained_model.get_weights().copy()

    prune_fraction = pruning_percent/100
    number_of_weights_to_be_pruned = int(prune_fraction*total_no_weights)
    weights_to_be_pruned = {k: all_weights_sorted[k] for k in list(all_weights_sorted)[ :  number_of_weights_to_be_pruned]}

    for k, v in weights_to_be_pruned.items():
        new_weights[k[0]][k[1], k[2]] = 0

    for layer_no in range(total_no_layers - 1) :
        new_layer_weights = new_weights[layer_no].reshape(1, new_weights[layer_no].shape[0], new_weights[layer_no].shape[1])
        new_model.layers[layer_no].set_weights(new_layer_weights)

    new_score  = new_model.evaluate(X_test_norm, Y_test_onehot, verbose=0)
    weight_pruning_scores .append(new_score[1])

all_neurons = {}

for layer_no in range(total_no_layers - 1):

    layer_neurons = {}
    layer_neurons_df = pd.DataFrame(trained_model.layers[layer_no].get_weights()[0])

    for i in range(len(layer_neurons_df.columns)):
        layer_neurons.update({ i : np.array( layer_neurons_df.iloc[:,i] ) })

    layer_neurons = { (layer_no, k): v for k, v in layer_neurons.items() }
    all_neurons.update(layer_neurons)

all_neurons_sorted = {k: v for k, v in sorted(all_neurons.items(), key=lambda item: np.linalg.norm(item[1], ord=2, axis=0))}

total_no_neurons = len(all_neurons_sorted)
total_no_neurons

neuron_pruning_scores = []

for pruning_percent in K:

    new_model = load_model("model.keras")
    new_weights = trained_model.get_weights().copy()

    prune_fraction = pruning_percent/100
    number_of_neurons_to_be_pruned = int(prune_fraction*total_no_neurons)
    neurons_to_be_pruned = {k: all_neurons_sorted[k] for k in list(all_neurons_sorted)[ : number_of_neurons_to_be_pruned]}

    for k, v in neurons_to_be_pruned.items():
        new_weights[k[0]][:, k[1]] = 0

    for layer_no in range(total_no_layers - 1) :
        new_layer_weights = new_weights[layer_no].reshape(1, new_weights[layer_no].shape[0], new_weights[layer_no].shape[1])
        new_model.layers[layer_no].set_weights(new_layer_weights)

    new_score  = new_model.evaluate(X_test_norm, Y_test_onehot, verbose=0)
    neuron_pruning_scores.append(new_score[1])

plt.figure(figsize=(8, 4))
plt.plot(pd.DataFrame(weight_pruning_scores).set_index(pd.Series(K), drop=True) , color='r')
plt.plot(pd.DataFrame(neuron_pruning_scores).set_index(pd.Series(K), drop=True) , color='b')
plt.title('Effect of Pruning on accuracy', weight='bold', fontsize=16)
plt.ylabel('Score', weight='bold', fontsize=14)
plt.xlabel('Pruning Percentage (K)', weight='bold', fontsize=14)
plt.xticks(weight='bold', fontsize=12)
plt.yticks(weight='bold', fontsize=12)
plt.legend(['Weight Pruning', 'Neuron Pruning'], loc='best', prop={'size': 14})
plt.grid(color = 'y', linewidth='0.5')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Generate synthetic activations before pruning (replace with actual data)
np.random.seed(42)
activations_before = np.random.randint(10, 100, (10, 10))  # 10x10 matrix with values from 10 to 99

# Simulate pruning by setting 30% of the neurons to zero
mask = np.random.rand(10, 10) < 0.3  # Mask where pruning happens
activations_after = activations_before.copy()
activations_after[mask] = 0  # Set pruned neurons to zero

# Define a blue color theme
cmap = sns.color_palette("Blues", as_cmap=True)

# Create a masked array for pruned neurons to avoid NaN issues
activations_plot = activations_after.astype(float)  # Convert to float so NaN can be assigned
activations_plot[mask] = np.nan  # Replace pruned neurons with NaN

# Create subplots for Before & After Pruning
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# **Before Pruning Heatmap**
sns.heatmap(activations_before, cmap=cmap, annot=True, fmt='.0f', linewidths=0.5, cbar=True,
            annot_kws={"color": "black"}, ax=axes[0], vmin=10, vmax=99)
axes[0].set_title("Neuron Activations Before Pruning")

# **After Pruning Heatmap (With Blacked-Out Pruned Neurons)**
ax = sns.heatmap(activations_plot, cmap=cmap, annot=True, fmt='.0f', linewidths=0.5, cbar=True,
                 annot_kws={"color": "black"}, mask=mask, ax=axes[1], vmin=10, vmax=99)

# Manually overlay black boxes on pruned neurons
for i in range(activations_after.shape[0]):
    for j in range(activations_after.shape[1]):
        if mask[i, j]:  # If neuron is pruned
            axes[1].add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color='black', edgecolor='black'))

axes[1].set_title("Neuron Activations After Pruning (Pruned = Black)")

plt.tight_layout()
plt.show()
10/04/25, 13:30 - Nishita ğŸª°: <Media omitted>
10/04/25, 13:38 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 13:39 - Nishita ğŸª°: <Media omitted>
10/04/25, 13:44 - rohxn 03: Now combine both in a single image
10/04/25, 13:47 - Nishita ğŸª°: <Media omitted>
10/04/25, 13:49 - rohxn 03: What graph is prefereble?
10/04/25, 13:49 - Nishita ğŸª°: Line plot what you say ??
10/04/25, 13:56 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 14:02 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 14:02 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 14:22 - rohxn 03: <Media omitted>
10/04/25, 14:23 - Nishita ğŸª°: I have seen this ğŸ¤£ğŸ¤£
10/04/25, 15:18 - Wifeyâ¤ï¸: 10.1109/TAFFC.2022.3226473
10/04/25, 16:01 - Nishita ğŸª°: import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# 1ï¸âƒ£ Build a Simple CNN Model
def create_model():
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name="conv1"),
        layers.MaxPooling2D((2, 2), name="pool1"),
        layers.Conv2D(64, (3, 3), activation='relu', name="conv2"),
        layers.MaxPooling2D((2, 2), name="pool2"),
        layers.Flatten(name="flatten"),
        layers.Dense(128, activation='relu', name="dense1"),
        layers.Dense(10, activation='softmax', name="output")
    ])
    return model

# 2ï¸âƒ£ Load Dataset (MNIST)
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)

# 3ï¸âƒ£ Train the Baseline Model
model = create_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("\nğŸ”¹ Baseline Model Summary:")
model.summary()

print("\nğŸš€ Training the baseline model...")
model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))

# 4ï¸âƒ£ Evaluate the Baseline Model
baseline_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]
print(f"âœ… Baseline Model Accuracy: {baseline_accuracy:.4f}")

# 5ï¸âƒ£ Define Filter Pruning Function
def prune_conv_layer(conv_layer, prune_ratio=0.5):
    """Prunes filters with the lowest L1 norm from a Conv2D layer."""
    weights = conv_layer.get_weights()
    kernel, bias = weights[0], weights[1]

    num_filters = kernel.shape[-1]  # Number of filters

    # Compute L1 norm of each filter
    l1_norms = np.sum(np.abs(kernel), axis=(0, 1, 2))

    # Get indices of filters to KEEP
    num_prune = int(num_filters * prune_ratio)
    keep_indices = np.argsort(l1_norms)[num_prune:]

    # Keep only selected filters
    new_kernel = kernel[..., keep_indices]
    new_bias = bias[keep_indices]

    # Create a new Conv2D layer with fewer filters
    new_conv_layer = tf.keras.layers.Conv2D(
        filters=len(keep_indices),
        kernel_size=conv_layer.kernel_size,
        strides=conv_layer.strides,
        padding=conv_layer.padding,
        activation=conv_layer.activation,
        use_bias=(bias is not None),
        name=conv_layer.name + "_pruned"
    )

    # Apply new weights to the layer
    new_conv_layer.build(conv_layer.input.shape)
    new_conv_layer.set_weights([new_kernel, new_bias])

    return new_conv_layer, len(keep_indices)

# 6ï¸âƒ£ Apply Pruning to the First Convolutional Layer
pruned_conv1, new_filters = prune_conv_layer(model.layers[0], prune_ratio=0.8)

# 7ï¸âƒ£ Modify Pooling Layer and Next Convolutional Layer
pruned_pool1 = layers.MaxPooling2D((2, 2), name="pool1_pruned")

# **FIX: Explicitly define input shape for conv2_pruned**
pruned_conv2 = layers.Conv2D(
    filters=64, kernel_size=(3, 3), activation='relu',
    input_shape=(13, 13, new_filters),  # **Ensure correct input shape**
    name="conv2_pruned"
)

pruned_pool2 = layers.MaxPooling2D((2, 2), name="pool2_pruned")

# **FIX: Ensure Flatten layer adapts to new shape**
pruned_flatten = layers.Flatten(name="flatten_pruned")

# 8ï¸âƒ£ Rebuild Model with Pruned Layers
new_model = keras.Sequential([
    layers.Input(shape=(28, 28, 1)),  # **Ensure input shape is set**
    pruned_conv1,
    pruned_pool1,
    pruned_conv2,
    pruned_pool2,
    pruned_flatten,
    model.layers[5],  # Dense
    model.layers[6],  # Output Layer
])

# 9ï¸âƒ£ Show Pruned Model Summary
print("\nğŸ”¹ Pruned Model Summary:")
new_model.build(input_shape=(None, 28, 28, 1))  # **Ensure layers are built**
new_model.summary()

# ğŸ”Ÿ Compile and Retrain the Pruned Model
new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("\nğŸš€ Retraining the pruned model...")
new_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))

# ğŸ”Ÿ Evaluate the Pruned Model
pruned_accuracy = new_model.evaluate(x_test, y_test, verbose=0)[1]
print(f"âœ… Pruned Model Accuracy: {pruned_accuracy:.4f}")

# ğŸ” Compare Results
print(f"\nğŸ“Š Accuracy Before Pruning: {baseline_accuracy:.4f}")
print(f"ğŸ“Š Accuracy After Pruning: {pruned_accuracy:.4f}")

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# 1ï¸âƒ£ Build a Simple CNN Model
def create_model():
    model = keras.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), name="conv1"),
        layers.MaxPooling2D((2, 2), name="pool1"),
        layers.Conv2D(64, (3, 3), activation='relu', name="conv2"),
        layers.MaxPooling2D((2, 2), name="pool2"),
        layers.Flatten(name="flatten"),
        layers.Dense(128, activation='relu', name="dense1"),
        layers.Dense(10, activation='softmax', name="output")
    ])
    return model

# 2ï¸âƒ£ Load Dataset (MNIST)
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)

# 3ï¸âƒ£ Train the Baseline Model
model = create_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("\nğŸ”¹ Baseline Model Summary:")
model.summary()

print("\nğŸš€ Training the baseline model...")
model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))

# 4ï¸âƒ£ Evaluate the Baseline Model
baseline_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]
print(f"âœ… Baseline Model Accuracy: {baseline_accuracy:.4f}")

# 5ï¸âƒ£ Define Filter Pruning Function
def prune_conv_layer(conv_layer, prune_ratio=0.5):
    """Prunes filters with the lowest L1 norm from a Conv2D layer."""
    weights = conv_layer.get_weights()
    kernel, bias = weights[0], weights[1]

    num_filters = kernel.shape[-1]  # Number of filters

    # Compute L1 norm of each filter
    l1_norms = np.sum(np.abs(kernel), axis=(0, 1, 2))

    # Get indices of filters to KEEP
    num_prune = int(num_filters * prune_ratio)
    keep_indices = np.argsort(l1_norms)[num_prune:]

    # Keep only selected filters
    new_kernel = kernel[..., keep_indices]
    new_bias = bias[keep_indices]

    # Create a new Conv2D layer with fewer filters
    new_conv_layer = layers.Conv2D(
        filters=len(keep_indices),
        kernel_size=conv_layer.kernel_size,
        strides=conv_layer.strides,
        padding=conv_layer.padding,
        activation=conv_layer.activation,
        use_bias=True,
        name=conv_layer.name + "_pruned"
    )

    # Apply new weights to the layer
    input_depth = kernel.shape[2]  # Preserve input depth
    new_conv_layer.build((None, None, None, input_depth))
    new_conv_layer.set_weights([new_kernel, new_bias])

    return new_conv_layer, len(keep_indices)

# 6ï¸âƒ£ Apply Pruning to the First Convolutional Layer
pruned_conv1, filters_conv1 = prune_conv_layer(model.layers[0], prune_ratio=0.8)

# 7ï¸âƒ£ Modify Pooling Layer to Match the New Output
pruned_pool1 = layers.MaxPooling2D((2, 2), name="pool1_pruned")

# 8ï¸âƒ£ Prune the Second Convolutional Layer to Match `conv1_pruned` Output Depth
original_conv2 = model.layers[2]  # Get the second Conv2D layer
pruned_conv2, filters_conv2 = prune_conv_layer(original_conv2, prune_ratio=0.5)

# ğŸ” Fix Input Depth Mismatch
pruned_conv2 = layers.Conv2D(
    filters=filters_conv2,
    kernel_size=original_conv2.kernel_size,
    strides=original_conv2.strides,
    padding=original_conv2.padding,
    activation=original_conv2.activation,
    use_bias=True,
    name=original_conv2.name + "_pruned"
)

# Ensure the input shape matches the output of `pruned_conv1`
pruned_conv2.build((None, None, None, pruned_conv1.filters))

# 9ï¸âƒ£ Modify Pooling Layer to Match the New Output
pruned_pool2 = layers.MaxPooling2D((2, 2), name="pool2_pruned")

# ğŸ”Ÿ Compute the Flattened Output Shape Dynamically
dummy_input = np.random.randn(1, 28, 28, 1).astype(np.float32)  # Sample input batch
intermediate_model = keras.Sequential([
    layers.Input(shape=(28, 28, 1)),
    pruned_conv1,
    pruned_pool1,
    pruned_conv2,
    pruned_pool2,
    layers.Flatten()
])

# Get the output shape of the Flatten layer dynamically
dummy_output = intermediate_model.predict(dummy_input)
flattened_dim = dummy_output.shape[1]  # Correct dimension for Dense layer

# ğŸ”Ÿ Rebuild Model with Pruned Layers
new_model = keras.Sequential([
    layers.Input(shape=(28, 28, 1)),
    pruned_conv1,
    pruned_pool1,
    pruned_conv2,
    pruned_pool2,
    layers.Flatten(),
    layers.Dense(128, activation='relu', name="dense1_pruned"),  # Fixing input shape
    layers.Dense(10, activation='softmax', name="output")  # Output Layer
])

# ğŸ”Ÿ Show Pruned Model Summary
print("\nğŸ”¹ Pruned Model Summary:")
new_model.build(input_shape=(None, 28, 28, 1))
new_model.summary()

# ğŸ”Ÿ Compile and Retrain the Pruned Model
new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

print("\nğŸš€ Retraining the pruned model...")
new_model.fit(x_train, y_train, epochs=2, validation_data=(x_test, y_test))

# ğŸ”Ÿ Evaluate the Pruned Model
pruned_accuracy = new_model.evaluate(x_test, y_test, verbose=0)[1]
print(f"âœ… Pruned Model Accuracy: {pruned_accuracy:.4f}")

# ğŸ” Compare Results
print(f"\nğŸ“Š Accuracy Before Pruning: {baseline_accuracy:.4f}")
print(f"ğŸ“Š Accuracy After Pruning: {pruned_accuracy:.4f}")
10/04/25, 16:21 - Nishita ğŸª°: import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

class TeacherModel(nn.Module):
    def __init__(self):
        super(TeacherModel, self).__init__()
        self.fc1 = nn.Linear(28*28, 1200)
        self.fc2 = nn.Linear(1200, 1200)
        self.fc3 = nn.Linear(1200, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

class StudentModel(nn.Module):
    def __init__(self):
        super(StudentModel, self).__init__()
        self.fc1 = nn.Linear(28*28, 800)
        self.fc2 = nn.Linear(800, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)

def distillation_loss(student_logits, teacher_logits, labels, temperature, alpha):
    soft_teacher = F.softmax(teacher_logits / temperature, dim=1)
    soft_student = F.log_softmax(student_logits / temperature, dim=1)
    kl_div = F.kl_div(soft_student, soft_teacher) * (temperature ** 2)
    ce_loss = F.cross_entropy(student_logits, labels)
    return alpha * kl_div + (1 - alpha) * ce_loss

teacher = TeacherModel()
optimizer = optim.Adam(teacher.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

def train_teacher(model, train_loader, optimizer, criterion, epochs=5):
    model.train()
    for epoch in range(epochs):
        for data, target in train_loader:
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
        print(f"Teacher Epoch {epoch+1}/{epochs}, Loss: {loss.item()}")

train_teacher(teacher, train_loader, optimizer, criterion)

student = StudentModel()
optimizer = optim.Adam(student.parameters(), lr=0.001)

def train_student(student, teacher, train_loader, optimizer, temperature=5.0, alpha=0.7, epochs=5):
    student.train()
    teacher.eval()
    for epoch in range(epochs):
        for data, target in train_loader:
            optimizer.zero_grad()
            student_logits = student(data)
            with torch.no_grad():
                teacher_logits = teacher(data)
            loss = distillation_loss(student_logits, teacher_logits, target, temperature, alpha)
            loss.backward()
            optimizer.step()
        print(f"Student Epoch {epoch+1}/{epochs}, Loss: {loss.item()}")

train_student(student, teacher, train_loader, optimizer)

def evaluate(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    accuracy = 100 * correct / total
    return accuracy




def count_parameters(model):
    return sum(p.numel() for p in model.parameters())

teacher_params = count_parameters(teacher)
student_params = count_parameters(student)

teacher_accuracy = evaluate(teacher, test_loader)
student_accuracy = evaluate(student, test_loader)

print(f"Teacher Model Parameters: {teacher_params}")
print(f"Student Model Parameters: {student_params}")

print(f"Teacher Accuracy: {teacher_accuracy:.2f}%, Parameters: {teacher_params}")
print(f"Student Accuracy: {student_accuracy:.2f}%, Parameters: {student_params}")
10/04/25, 16:55 - Wifeyâ¤ï¸: <Media omitted>
10/04/25, 16:56 - rohxn 03: Guys finally we sexessfully finished our ml algorithm project
10/04/25, 16:57 - rohxn 03: @916364562073 here everything is there 
Unzip and learn ok, last moment i cant teach u
16 th is the final date
10/04/25, 17:06 - Gass: Ok
10/04/25, 21:34 - rohxn 03: @919663957450 I might need ur lap tomorrow
10/04/25, 21:35 - rohxn 03: Either talk to appa and stay with me till 8 or 9

Or hand me ur lap
10/04/25, 21:40 - Wifeyâ¤ï¸: 8 or 9
10/04/25, 21:40 - Wifeyâ¤ï¸: Ahh
10/04/25, 21:44 - rohxn 03: 1. Give the lap and leave at 5
2. Be with me till appa comes and pick u, so u can take ur lap to home
3. U do the main part from home and leave early 

Choose ur option, im fine with all three
10/04/25, 22:16 - Nishita ğŸª°: For what you need ??
10/04/25, 22:26 - rohxn 03: Gaming and nlp
10/04/25, 22:26 - Nishita ğŸª°: R u free ??
10/04/25, 22:27 - rohxn 03: Yasss
11/04/25, 20:52 - Nishita ğŸª°: @916238330557 and @919663957450 tmr my elective class is till 12 okk
11/04/25, 20:52 - Wifeyâ¤ï¸: ha okay pa
11/04/25, 20:56 - rohxn 03: We will leave at 1 15
11/04/25, 20:57 - Wifeyâ¤ï¸: okkkkkkkkkk
11/04/25, 20:57 - Nishita ğŸª°: Okkk
11/04/25, 20:57 - Nishita ğŸª°: @916238330557 Vidith is saying he can't add us to grp
11/04/25, 20:57 - Nishita ğŸª°: So @919663957450 ask Sir for the grp link
11/04/25, 20:57 - rohxn 03: Ok
12/04/25, 08:04 - rohxn 03: @918799146002 Dont forget gum and ur laptop
12/04/25, 08:40 - Nishita ğŸª°: Ok
12/04/25, 09:26 - Wifeyâ¤ï¸: @918799146002 where are you
12/04/25, 10:14 - Nishita ğŸª°: I came now to clg
12/04/25, 10:14 - Nishita ğŸª°: Where are you ??
12/04/25, 10:14 - Nishita ğŸª°: I am going class
12/04/25, 10:22 - Wifeyâ¤ï¸: Yes, for this lab I have only made a single report
12/04/25, 10:22 - Wifeyâ¤ï¸: Yes I have mentioned all the topics in a single report
12/04/25, 10:22 - Wifeyâ¤ï¸: Thera is only two main topic shap and lime
12/04/25, 10:22 - Wifeyâ¤ï¸: ohh okay okay only this much is enough ryt
12/04/25, 10:22 - Wifeyâ¤ï¸: Yes
12/04/25, 10:22 - Wifeyâ¤ï¸: there is no need to do 6 records and all
12/04/25, 10:22 - Wifeyâ¤ï¸: I don't think so
12/04/25, 10:22 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 10:23 - Wifeyâ¤ï¸: i asked Yashwant like for the lab 9 should we prepare  lab records for each file and he sent this
12/04/25, 10:23 - Wifeyâ¤ï¸: soo can i also do this
12/04/25, 10:24 - Wifeyâ¤ï¸: or i should make lab records for each file
12/04/25, 10:25 - Nishita ğŸª°: As you think but it mentions only about 2 things only not the other activities
12/04/25, 10:26 - Nishita ğŸª°: We have done for text and something else also
12/04/25, 10:26 - Wifeyâ¤ï¸: how u did records for each file u done??
12/04/25, 10:26 - Nishita ğŸª°: Not yet still doing 
Yashwant had assigned some work so I was doing that
12/04/25, 10:26 - Nishita ğŸª°: Where are you??
12/04/25, 10:26 - Wifeyâ¤ï¸: lh4
12/04/25, 10:27 - Wifeyâ¤ï¸: sorry LH3
12/04/25, 10:27 - Nishita ğŸª°: U need laptop ??
12/04/25, 10:27 - Wifeyâ¤ï¸: illaa im doing but im confused how to do the record antahaa
12/04/25, 10:28 - Nishita ğŸª°: Like how we did for lab 4
12/04/25, 10:29 - Wifeyâ¤ï¸: ahh like part a .b. c d like taht till 6 files ryt
12/04/25, 10:32 - Nishita ğŸª°: Yess
12/04/25, 10:32 - Nishita ğŸª°: When will you the game ??
12/04/25, 10:38 - rohxn 03: When im in the gameğŸ˜
12/04/25, 10:39 - Nishita ğŸª°: Ayoo karma ve
12/04/25, 10:39 - Nishita ğŸª°: I am asking when will you do antha ?
12/04/25, 11:45 - rohxn 03: Lets seeeeee
12/04/25, 20:21 - Wifeyâ¤ï¸: null
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:21 - Wifeyâ¤ï¸: <Media omitted>
12/04/25, 20:29 - rohxn 03: Minors work thumba ide, im thinking how can i come naaleğŸ˜­
12/04/25, 20:29 - Wifeyâ¤ï¸: It's okay
12/04/25, 20:29 - Wifeyâ¤ï¸: We will finish this soon
12/04/25, 20:46 - rohxn 03: WhennnnnnnğŸ˜­ğŸ˜­
12/04/25, 21:54 - Wifeyâ¤ï¸: Hey
12/04/25, 21:54 - Wifeyâ¤ï¸: Tomorrow at what time we have to be there???
12/04/25, 21:55 - Wifeyâ¤ï¸: Just txt I'm going to sleep nowğŸ™‚
13/04/25, 10:15 - rohxn 03: ML Algorithm tasks:
1. Remove plagiarism -@919663957450 have to do @918799146002 have to guide her 
2. @919663957450 Give me clarity regarding the lab work where we reached

NLP task:
1. Creating report - I will do the report, @918799146002  review it and tell me what and all should we include if any
2. Creating a project - I will do

ARVR tasks
1. Should create UI-@918799146002 Help me to create a UI the rest everything ill take care
13/04/25, 10:15 - rohxn 03: I hope I've included everything, if not pls do let me know
13/04/25, 10:18 - Nishita ğŸª°: For plagiarism we need to check with small se tools ?? Or any other ??
13/04/25, 10:19 - rohxn 03: Small se tool u try
I dont think it would be useful
Because we took everything from ai tool ryt
13/04/25, 10:19 - rohxn 03: Small se helps to find from internet
13/04/25, 10:19 - rohxn 03: We will try
13/04/25, 10:20 - Nishita ğŸª°: Then for the constitution we used that one ??
13/04/25, 10:20 - rohxn 03: @919663957450 Put our research paper in both small se tool and zero gpt and take a ss analytics and sent in grp
13/04/25, 10:20 - rohxn 03: Yeah
13/04/25, 11:54 - Wifeyâ¤ï¸: lab record till 8 everything finished ,,  lab 9 and 10 is left that's it
13/04/25, 11:55 - Wifeyâ¤ï¸: code file I will send u
13/04/25, 11:55 - Wifeyâ¤ï¸: 9 and 10
